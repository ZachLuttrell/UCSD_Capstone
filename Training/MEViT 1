{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNR8xjVhpPp/N6SvO1rpU6/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MEViT\n","\n","In this notebook I will attempt to implement the MEViT network architecture.\n","\n","**NOTE:** Connect to a High-RAM Environment"],"metadata":{"id":"6z4CZeVOowB4"}},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"szU0egT7tBFP"}},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"8nAk5_E-pMPE"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YgBD9gDcovEY","executionInfo":{"status":"ok","timestamp":1717009345266,"user_tz":420,"elapsed":33400,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"53dba062-83b3-4fa1-c33f-4711dfad4fb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","# Imports\n","import os\n","import cv2\n","import numpy as np\n","import tifffile as tiff\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import LayerNormalization, Dense, Dropout, Flatten, Conv2DTranspose\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["Data Loading"],"metadata":{"id":"0Kt6_4oqpOKr"}},{"cell_type":"code","source":["# Function to count files\n","def count_files(directory, extension=\".tif\"):\n","    return sum(1 for file in os.listdir(directory) if file.endswith(extension))\n","\n","# Paths to your image and mask directories\n","image_directory = '/gdrive/My Drive/Dataset/patches/train/images/'\n","mask_directory = '/gdrive/My Drive/Dataset/patches/train/masks/'\n","\n","# Counting the TIFF files in both directories\n","image_count = count_files(image_directory)\n","mask_count = count_files(mask_directory)\n","\n","print(f\"Number of image files: {image_count}\")\n","print(f\"Number of mask files: {mask_count}\")\n","\n","# Load the images and masks into the lists below\n","images = []\n","masks = []\n","\n","# Sort filenames to ensure matching pairs align\n","image_files = sorted([f for f in os.listdir(image_directory) if f.endswith(\".tif\")])\n","mask_files = sorted([f for f in os.listdir(mask_directory) if f.endswith(\".tif\")])\n","\n","# Determine how many files to load based on percentage\n","percentage_to_load = 20 / 100.0  # Set the % of dataset to be loaded here.\n","number_of_files_to_load = int(len(image_files) * percentage_to_load)\n","\n","# Create a mapping of image names to their corresponding mask names by removing '_Buildings'\n","image_to_mask = {f: f.replace(\"_patch\", \"_Buildings_patch\") for f in image_files}\n","\n","# Only iterate over the subset of files determined by the percentage\n","print(f'Attempting to load {percentage_to_load*100}% of dataset: {number_of_files_to_load} images/mask pairs...')\n","for count, image_name in enumerate(image_files[:number_of_files_to_load], start=1):\n","    img_path = os.path.join(image_directory, image_name)\n","    mask_name = image_to_mask[image_name]\n","    mask_path = os.path.join(mask_directory, mask_name)\n","\n","    if os.path.exists(mask_path):\n","        img = tiff.imread(img_path)\n","        mask = tiff.imread(mask_path)\n","\n","        images.append(img)\n","        masks.append(mask)\n","    else:\n","        print(f'\\nMask not found for image: {image_name}')\n","\n","    # Update the count in the same line\n","    print(f'\\rProcessed: {count}/{number_of_files_to_load}', end='')\n","\n","print(\"\\nLoading complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SO8PR--pASc","executionInfo":{"status":"ok","timestamp":1717009942169,"user_tz":420,"elapsed":596911,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"15128e10-a9c9-4c2b-eb3f-33d310093101"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of image files: 4787\n","Number of mask files: 4787\n","Attempting to load 20.0% of dataset: 957 images/mask pairs...\n","Processed: 957/957\n","Loading complete.\n"]}]},{"cell_type":"markdown","source":["Normalization & Train/Test/Val Split"],"metadata":{"id":"SKX6H6GnpaRB"}},{"cell_type":"code","source":["# Convert the lists to numpy arrays\n","images = np.array(images, dtype=np.float32)\n","masks = np.array(masks, dtype=np.float32)\n","\n","# Normalize the values\n","images /= 255.0\n","masks /= 255.0\n","masks = masks.reshape((-1, 256, 256, 1))\n","\n","# Split the data into training and test sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=1995)\n","\n","# Further split the training set into training and validation sets (90% train, 10% val)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1995)\n","\n","# If there is an unnecessary singleton dimension in your dataset, remove it:\n","if X_train.ndim > 3:\n","    X_train = X_train.squeeze(axis=1)\n","    X_val = X_val.squeeze(axis=1)\n","    X_test = X_test.squeeze(axis=1)\n","\n","# Display the shapes of the datasets to confirm correct dimensions\n","print('Dataset Shapes:')\n","print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n","print(f'X_val:   {X_val.shape}, y_val: {y_val.shape}')\n","print(f'X_test:  {X_test.shape}, y_test: {y_test.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyWjq5-vpcif","executionInfo":{"status":"ok","timestamp":1717009942171,"user_tz":420,"elapsed":25,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"c44164be-1d6f-4e53-a493-c0129eed64d3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Shapes:\n","X_train: (688, 256, 256, 3), y_train: (688, 256, 256, 1)\n","X_val:   (77, 256, 256, 3), y_val: (77, 256, 256, 1)\n","X_test:  (192, 256, 256, 3), y_test: (192, 256, 256, 1)\n"]}]},{"cell_type":"markdown","source":["Model Definition"],"metadata":{"id":"85MNZvtrpuar"}},{"cell_type":"code","source":["from sklearn.utils.class_weight import compute_class_weight\n","from keras.callbacks import LearningRateScheduler\n","\n","# Custom Metrics\n","def dice_coefficient(y_true, y_pred, threshold=0.5):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + tf.keras.backend.epsilon())\n","\n","def jaccard_index(y_true, y_pred, threshold=0.5):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    union = tf.reduce_sum(y_true_f + y_pred_f) - intersection\n","    return (intersection + tf.keras.backend.epsilon()) / (union + tf.keras.backend.epsilon())\n","\n","def sensitivity(y_true, y_pred):\n","    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1)))\n","    return true_positives / (possible_positives + tf.keras.backend.epsilon())\n","\n","def specificity(y_true, y_pred):\n","    true_negatives = tf.reduce_sum(tf.round(tf.clip_by_value((1-y_true) * (1-y_pred), 0, 1)))\n","    possible_negatives = tf.reduce_sum(tf.round(tf.clip_by_value(1-y_true, 0, 1)))\n","    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n","\n","def precision(y_true, y_pred):\n","    true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))\n","    predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1)))\n","    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","\n","# Loss Function\n","def calculate_class_weights(masks):\n","    flat_labels = masks.flatten().astype(int)\n","    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(flat_labels), y=flat_labels)\n","    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","    return class_weights_dict\n","\n","def weighted_binary_crossentropy(weights):\n","    def loss(y_true, y_pred):\n","        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n","        weighted_bce = bce * (weights[1] * y_true + weights[0] * (1 - y_true))\n","        return tf.keras.backend.mean(weighted_bce)\n","    return loss\n","\n","# Calculate the class weights for the training masks\n","class_weights = calculate_class_weights(y_train)\n","print(\"Class weights:\", class_weights)\n","weighted_loss = weighted_binary_crossentropy(class_weights)\n","\n","# Learning rate schedule\n","def lr_schedule(epoch, lr):\n","    if epoch >= 40 and epoch < 60:\n","        return lr * 0.1\n","    elif epoch >= 60:\n","        return lr * 0.1\n","    return lr\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","# Define the MEVit model\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = models.Sequential([\n","            layers.Dense(ff_dim, activation='relu'),\n","            layers.Dense(embed_dim),\n","        ])\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","def create_vit_segmentation_model(input_shape, num_classes, embed_dim, num_heads, ff_dim):\n","    inputs = layers.Input(shape=input_shape)\n","    # Flatten the input\n","    x = layers.Reshape((-1, input_shape[-1]))(inputs)\n","\n","    # Create patches and embed\n","    patch_size = 16\n","    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n","    patches = layers.Conv2D(filters=embed_dim, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(inputs)\n","    patches = layers.Reshape((num_patches, embed_dim))(patches)\n","\n","    # Add Transformer blocks\n","    for _ in range(8):\n","        patches = TransformerBlock(embed_dim, num_heads, ff_dim)(patches)\n","\n","    # Reshape back to image\n","    x = layers.Reshape((input_shape[0] // patch_size, input_shape[1] // patch_size, embed_dim))(patches)\n","    x = Conv2DTranspose(num_classes, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(x)\n","    outputs = layers.Activation('sigmoid')(x)\n","\n","    return Model(inputs, outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRgTuRcepv8d","executionInfo":{"status":"ok","timestamp":1717009947040,"user_tz":420,"elapsed":4887,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"d7e552dd-14f3-4a5f-9a86-83d295ddff72"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Class weights: {0: 0.533457059946358, 1: 7.972264460799221}\n"]}]},{"cell_type":"markdown","source":["Model Compilation"],"metadata":{"id":"iVA6ln9zp-Ke"}},{"cell_type":"code","source":["from keras.optimizers import SGD\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","input_shape = (256, 256, 3)\n","num_classes = 1\n","embed_dim = 64\n","num_heads = 4\n","ff_dim = 128\n","\n","model = create_vit_segmentation_model(input_shape, num_classes, embed_dim, num_heads, ff_dim)\n","model.summary()\n","\n","# Compile the model\n","sgd = SGD(learning_rate=0.01, momentum=0.9)\n","model.compile(\n","    optimizer=sgd,\n","    loss=weighted_loss,\n","    metrics=['accuracy', dice_coefficient, jaccard_index, sensitivity, specificity, precision]\n",")\n","\n","# Setup callbacks\n","early_stopping = EarlyStopping(\n","    monitor='val_dice_coefficient',\n","    patience=10,\n","    verbose=1,\n","    restore_best_weights=True\n",")\n","\n","model_checkpoint = ModelCheckpoint(\n","    '/gdrive/My Drive/Dataset/Models/best_mevit_model',  # Path where the model will be saved\n","    monitor='val_dice_coefficient',  # Save the model based on the maximum dice_coefficient value\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yOa_BtwAqWNK","executionInfo":{"status":"ok","timestamp":1717010845806,"user_tz":420,"elapsed":1639,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"b424bad2-9996-4fb9-cd8e-1ab85d0c1b85"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 16, 16, 64)        49216     \n","                                                                 \n"," reshape_4 (Reshape)         (None, 256, 64)           0         \n","                                                                 \n"," transformer_block_8 (Trans  (None, 256, 64)           83200     \n"," formerBlock)                                                    \n","                                                                 \n"," transformer_block_9 (Trans  (None, 256, 64)           83200     \n"," formerBlock)                                                    \n","                                                                 \n"," transformer_block_10 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," transformer_block_11 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," transformer_block_12 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," transformer_block_13 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," transformer_block_14 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," transformer_block_15 (Tran  (None, 256, 64)           83200     \n"," sformerBlock)                                                   \n","                                                                 \n"," reshape_5 (Reshape)         (None, 16, 16, 64)        0         \n","                                                                 \n"," conv2d_transpose_1 (Conv2D  (None, 256, 256, 1)       16385     \n"," Transpose)                                                      \n","                                                                 \n"," activation_1 (Activation)   (None, 256, 256, 1)       0         \n","                                                                 \n","=================================================================\n","Total params: 731201 (2.79 MB)\n","Trainable params: 731201 (2.79 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Model Training"],"metadata":{"id":"9pd10BmVsJJc"}},{"cell_type":"code","source":["# Fit the model\n","history = model.fit(\n","    X_train, y_train,\n","    batch_size=16,\n","    epochs=70,\n","    verbose=1,\n","    validation_data=(X_val, y_val),\n","    callbacks=[early_stopping, model_checkpoint, lr_scheduler]\n",")\n","\n","# Save the model\n","model.save('/gdrive/My Drive/Dataset/Models/mevit_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k8N1wpf-sKt8","executionInfo":{"status":"ok","timestamp":1717011289473,"user_tz":420,"elapsed":432735,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"87953bc6-71f3-4180-cc79-255e98f243bd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.5283 - dice_coefficient: 0.1100 - jaccard_index: 0.0583 - sensitivity: 0.4676 - specificity: 0.5325 - precision: 0.0627\n","Epoch 1: val_dice_coefficient improved from -inf to 0.10313, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 48s 993ms/step - loss: 0.6941 - accuracy: 0.5283 - dice_coefficient: 0.1100 - jaccard_index: 0.0583 - sensitivity: 0.4676 - specificity: 0.5325 - precision: 0.0627 - val_loss: 0.6629 - val_accuracy: 0.5277 - val_dice_coefficient: 0.1031 - val_jaccard_index: 0.0545 - val_sensitivity: 0.4746 - val_specificity: 0.5309 - val_precision: 0.0581 - lr: 0.0100\n","Epoch 2/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5921 - dice_coefficient: 0.1083 - jaccard_index: 0.0574 - sensitivity: 0.3989 - specificity: 0.6054 - precision: 0.0634\n","Epoch 2: val_dice_coefficient improved from 0.10313 to 0.10542, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 43s 1000ms/step - loss: 0.6938 - accuracy: 0.5921 - dice_coefficient: 0.1083 - jaccard_index: 0.0574 - sensitivity: 0.3989 - specificity: 0.6054 - precision: 0.0634 - val_loss: 0.6627 - val_accuracy: 0.4833 - val_dice_coefficient: 0.1054 - val_jaccard_index: 0.0558 - val_sensitivity: 0.5315 - val_specificity: 0.4803 - val_precision: 0.0587 - lr: 0.0100\n","Epoch 3/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4984 - dice_coefficient: 0.1129 - jaccard_index: 0.0600 - sensitivity: 0.5120 - specificity: 0.4979 - precision: 0.0639\n","Epoch 3: val_dice_coefficient improved from 0.10542 to 0.10769, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 41s 950ms/step - loss: 0.6934 - accuracy: 0.4984 - dice_coefficient: 0.1129 - jaccard_index: 0.0600 - sensitivity: 0.5120 - specificity: 0.4979 - precision: 0.0639 - val_loss: 0.6627 - val_accuracy: 0.4195 - val_dice_coefficient: 0.1077 - val_jaccard_index: 0.0570 - val_sensitivity: 0.6112 - val_specificity: 0.4079 - val_precision: 0.0593 - lr: 0.0100\n","Epoch 4/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4432 - dice_coefficient: 0.1156 - jaccard_index: 0.0616 - sensitivity: 0.5850 - specificity: 0.4342 - precision: 0.0648\n","Epoch 4: val_dice_coefficient improved from 0.10769 to 0.11271, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 41s 954ms/step - loss: 0.6931 - accuracy: 0.4432 - dice_coefficient: 0.1156 - jaccard_index: 0.0616 - sensitivity: 0.5850 - specificity: 0.4342 - precision: 0.0648 - val_loss: 0.6615 - val_accuracy: 0.4879 - val_dice_coefficient: 0.1127 - val_jaccard_index: 0.0599 - val_sensitivity: 0.5676 - val_specificity: 0.4829 - val_precision: 0.0628 - lr: 0.0100\n","Epoch 5/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.5246 - dice_coefficient: 0.1199 - jaccard_index: 0.0640 - sensitivity: 0.5190 - specificity: 0.5253 - precision: 0.0685\n","Epoch 5: val_dice_coefficient improved from 0.11271 to 0.12041, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 41s 962ms/step - loss: 0.6918 - accuracy: 0.5246 - dice_coefficient: 0.1199 - jaccard_index: 0.0640 - sensitivity: 0.5190 - specificity: 0.5253 - precision: 0.0685 - val_loss: 0.6592 - val_accuracy: 0.4861 - val_dice_coefficient: 0.1204 - val_jaccard_index: 0.0643 - val_sensitivity: 0.6117 - val_specificity: 0.4784 - val_precision: 0.0670 - lr: 0.0100\n","Epoch 6/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6889 - accuracy: 0.4846 - dice_coefficient: 0.1313 - jaccard_index: 0.0705 - sensitivity: 0.6226 - specificity: 0.4754 - precision: 0.0739\n","Epoch 6: val_dice_coefficient did not improve from 0.12041\n","43/43 [==============================] - 32s 734ms/step - loss: 0.6889 - accuracy: 0.4846 - dice_coefficient: 0.1313 - jaccard_index: 0.0705 - sensitivity: 0.6226 - specificity: 0.4754 - precision: 0.0739 - val_loss: 0.6595 - val_accuracy: 0.3330 - val_dice_coefficient: 0.1200 - val_jaccard_index: 0.0640 - val_sensitivity: 0.7923 - val_specificity: 0.3048 - val_precision: 0.0651 - lr: 0.0100\n","Epoch 7/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6880 - accuracy: 0.6389 - dice_coefficient: 0.1284 - jaccard_index: 0.0690 - sensitivity: 0.4546 - specificity: 0.6506 - precision: 0.0788\n","Epoch 7: val_dice_coefficient improved from 0.12041 to 0.12330, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 42s 985ms/step - loss: 0.6880 - accuracy: 0.6389 - dice_coefficient: 0.1284 - jaccard_index: 0.0690 - sensitivity: 0.4546 - specificity: 0.6506 - precision: 0.0788 - val_loss: 0.6582 - val_accuracy: 0.4902 - val_dice_coefficient: 0.1233 - val_jaccard_index: 0.0659 - val_sensitivity: 0.6248 - val_specificity: 0.4813 - val_precision: 0.0686 - lr: 0.0100\n","Epoch 8/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.5206 - dice_coefficient: 0.1468 - jaccard_index: 0.0797 - sensitivity: 0.6546 - specificity: 0.5114 - precision: 0.0852\n","Epoch 8: val_dice_coefficient improved from 0.12330 to 0.14431, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 40s 937ms/step - loss: 0.6837 - accuracy: 0.5206 - dice_coefficient: 0.1468 - jaccard_index: 0.0797 - sensitivity: 0.6546 - specificity: 0.5114 - precision: 0.0852 - val_loss: 0.6543 - val_accuracy: 0.8924 - val_dice_coefficient: 0.1443 - val_jaccard_index: 0.0787 - val_sensitivity: 0.1489 - val_specificity: 0.9370 - val_precision: 0.1492 - lr: 0.0100\n","Epoch 9/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6777 - accuracy: 0.6075 - dice_coefficient: 0.1647 - jaccard_index: 0.0901 - sensitivity: 0.6136 - specificity: 0.6082 - precision: 0.1028\n","Epoch 9: val_dice_coefficient improved from 0.14431 to 0.17860, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model\n","43/43 [==============================] - 41s 962ms/step - loss: 0.6777 - accuracy: 0.6075 - dice_coefficient: 0.1647 - jaccard_index: 0.0901 - sensitivity: 0.6136 - specificity: 0.6082 - precision: 0.1028 - val_loss: 0.6348 - val_accuracy: 0.6690 - val_dice_coefficient: 0.1786 - val_jaccard_index: 0.0987 - val_sensitivity: 0.6237 - val_specificity: 0.6686 - val_precision: 0.1046 - lr: 0.0100\n","Epoch 10/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.5895 - dice_coefficient: 0.1761 - jaccard_index: 0.0973 - sensitivity: 0.6575 - specificity: 0.5841 - precision: 0.1096\n","Epoch 10: val_dice_coefficient did not improve from 0.17860\n","43/43 [==============================] - 31s 726ms/step - loss: 0.6702 - accuracy: 0.5895 - dice_coefficient: 0.1761 - jaccard_index: 0.0973 - sensitivity: 0.6575 - specificity: 0.5841 - precision: 0.1096 - val_loss: 0.6276 - val_accuracy: 0.6328 - val_dice_coefficient: 0.1753 - val_jaccard_index: 0.0966 - val_sensitivity: 0.6775 - val_specificity: 0.6273 - val_precision: 0.1009 - lr: 0.0100\n","Epoch 11/70\n","43/43 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.5920 - dice_coefficient: 0.1816 - jaccard_index: 0.1007 - sensitivity: 0.6863 - specificity: 0.5858 - precision: 0.1087Restoring model weights from the end of the best epoch: 1.\n","\n","Epoch 11: val_dice_coefficient did not improve from 0.17860\n","43/43 [==============================] - 31s 732ms/step - loss: 0.6623 - accuracy: 0.5920 - dice_coefficient: 0.1816 - jaccard_index: 0.1007 - sensitivity: 0.6863 - specificity: 0.5858 - precision: 0.1087 - val_loss: 0.6272 - val_accuracy: 0.6248 - val_dice_coefficient: 0.1767 - val_jaccard_index: 0.0973 - val_sensitivity: 0.7018 - val_specificity: 0.6180 - val_precision: 0.1013 - lr: 0.0100\n","Epoch 11: early stopping\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"XpKxuoOXtGOe"}},{"cell_type":"markdown","source":["Evaluation"],"metadata":{"id":"eEY45m0AsTyF"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","# Evaluation functions\n","def plot_training_history(history):\n","    plt.figure(figsize=(12, 6))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Loss Over Epochs')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['dice_coefficient'], label='Training Dice Coefficient')\n","    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coefficient')\n","    plt.title('Dice Coefficient Over Epochs')\n","    plt.legend()\n","\n","    plt.show()\n","\n","def show_predictions(X, y_true, y_pred, num_samples=5):\n","    indices = np.random.choice(range(len(X)), num_samples, replace=False)\n","\n","    for i in indices:\n","        plt.figure(figsize=(12, 6))\n","        plt.subplot(1, 3, 1)\n","        plt.imshow(X[i])\n","        plt.title(f'Original Image [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 2)\n","        plt.imshow(y_true[i].squeeze(), cmap='gray')\n","        plt.title(f'True Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 3)\n","        plt.imshow(y_pred[i].squeeze() > 0.5, cmap='gray')  # Apply a threshold to convert probabilities to binary mask\n","        plt.title(f'Predicted Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.show()\n","\n","def plot_confusion_matrix(y_true, y_pred):\n","    y_true_f = y_true.flatten()\n","    y_pred_f = (y_pred.flatten() > 0.5).astype(int)  # Thresholding probabilities\n","\n","    cm = confusion_matrix(y_true_f, y_pred_f)\n","    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the confusion matrix\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","\n","    labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']\n","    counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n","    percentages = [\"{0:.2%}\".format(value) for value in cm_normalized.flatten()]\n","\n","    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(labels, counts, percentages)]\n","    labels = np.asarray(labels).reshape(2, 2)\n","\n","    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, center=0)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Perform the evaluation\n","plot_training_history(history)\n","y_pred = model.predict(X_test)\n","show_predictions(X_test, y_test, y_pred)\n","plot_confusion_matrix(y_test, y_pred)\n","print(classification_report(y_test.flatten(), (y_pred.flatten() > 0.5).astype(int)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1m3z1uO7ir7b7AtMhr5dmofE-PZem3K2E"},"id":"A3QbrIXpsU9K","executionInfo":{"status":"ok","timestamp":1717011454531,"user_tz":420,"elapsed":52940,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"b0362938-304a-4ab7-a4a2-03fafdc293f2"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}