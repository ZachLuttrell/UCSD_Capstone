{"cells":[{"cell_type":"markdown","metadata":{"id":"6z4CZeVOowB4"},"source":["# HRNet_w48\n","This is the first implementation of HRNet w48 directly from the segmentation_models_torch library.\n","\n","\n","**NOTE:** Connect to a High-RAM Environment with GPU enabled"]},{"cell_type":"markdown","metadata":{"id":"szU0egT7tBFP"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"5mU7Z6Bm3MWK"},"source":["Settings"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-7ruruAJ3Noc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719274898717,"user_tz":420,"elapsed":149885,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"c761e13c-c8b8-4b52-e387-c735e2d44ea7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation-models-pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.18.0+cu121)\n","Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation-models-pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0+cu121)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.23.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.15.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (24.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.31.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2024.6.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=5b2204116b38c1370cbf1e9681e462e0f31c2054149373c887274af63ffe103d\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60945 sha256=39b042fdfed0abed4b3337bfc278684b49edd703064a047e055488a75413583c\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, munch, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","\n","SETTINGS:\n","Model Name: hrnet_w48\n","Percentage to Load: 50.0%\n","Threshold: 0.25\n","Initial Learning Rate: 0.01\n","\n","GPU:\n","No GPU available, using the CPU instead.\n","\n","Mounted at /gdrive\n","\n","\n","LOADING COMPLETE...\n"]}],"source":["import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, random_split\n","from torch.optim import Adam\n","import os\n","import cv2\n","import numpy as np\n","import tifffile as tiff\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","!pip install segmentation-models-pytorch\n","import segmentation_models_pytorch as smp\n","\n","# MODEL SETTINGS\n","model_name = 'hrnet_w48'  # Updated model name\n","percentage_to_load = 50 / 100.0  # Set the % of dataset to be loaded here.\n","threshold = 0.25  # Set the threshold for metrics here\n","initial_lr = 0.01  # Learning rate at the beginning of training\n","print(f'\\nSETTINGS:')\n","print(f'Model Name: {model_name}')\n","print(f'Percentage to Load: {percentage_to_load*100}%')\n","print(f'Threshold: {threshold}')\n","print(f'Initial Learning Rate: {initial_lr}')\n","print()\n","\n","# Check for GPU availability\n","print('GPU:')\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(\"Num GPUs Available:\", torch.cuda.device_count())\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"No GPU available, using the CPU instead.\")\n","print()\n","\n","# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","print(f'\\nLOADING COMPLETE...')"]},{"cell_type":"markdown","metadata":{"id":"0Kt6_4oqpOKr"},"source":["Data Loading"]},{"cell_type":"code","source":["class SemanticSegmentationDataset(Dataset):\n","    def __init__(self, image_dir, mask_dir, percentage_to_load, transform=None):\n","        self.image_dir = image_dir\n","        self.mask_dir = mask_dir\n","        self.transform = transform\n","\n","        # Load file names\n","        self.image_files = self.get_sorted_files(image_dir)\n","        self.mask_files = self.get_sorted_files(mask_dir, expected_files=self.image_files)\n","\n","        # Determine how many files to load based on percentage\n","        number_of_files_to_load = int(len(self.image_files) * percentage_to_load)\n","        print(f'Loading {percentage_to_load*100}% of dataset: {number_of_files_to_load} images/mask pairs...')\n","\n","        # Limit the list to the required amount\n","        self.image_files = self.image_files[:number_of_files_to_load]\n","        self.mask_files = self.mask_files[:number_of_files_to_load]\n","\n","    def get_sorted_files(self, directory, extension=\".tif\", expected_files=None):\n","        files = sorted([f for f in os.listdir(directory) if f.endswith(extension)])\n","        if expected_files is not None:\n","            # Ensure the mask files match the image files by name modification rules\n","            expected_files = {f.replace(\"_patch\", \"_Buildings_patch\") for f in expected_files}\n","            files = [f for f in files if f in expected_files]\n","        return files\n","\n","    def __len__(self):\n","        return len(self.image_files)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.image_dir, self.image_files[idx])\n","        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n","\n","        try:\n","            image = tiff.imread(img_path)\n","            mask = tiff.imread(mask_path)\n","\n","            sample = {'image': image, 'mask': mask}\n","\n","            if self.transform:\n","                sample = self.transform(sample)\n","\n","            return sample\n","        except Exception as e:\n","            print(f'Error loading image/mask pair at index {idx}: {e}')\n","            raise e\n","\n","# Define the transformations\n","class CustomTransform:\n","    def __call__(self, sample):\n","        image, mask = sample['image'], sample['mask']\n","        # Adjust for channel first format and normalize to 0-1 range\n","        image = torch.from_numpy(image.transpose((2, 0, 1)).astype(np.float32) / 255.0)\n","        mask = torch.from_numpy(mask.astype(np.float32) / 255.0)\n","        return {'image': image, 'mask': mask}\n","\n","transform = CustomTransform()\n","\n","# Directory paths\n","image_directory = '/gdrive/My Drive/Dataset/patches/train/images/'\n","mask_directory = '/gdrive/My Drive/Dataset/patches/train/masks/'\n","\n","# Initialize dataset\n","dataset = SemanticSegmentationDataset(image_directory, mask_directory, percentage_to_load, transform=transform)\n","\n","# DataLoader for batching\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n","\n","print(f\"Training on {len(train_dataset)} samples, validating on {len(val_dataset)} samples.\")"],"metadata":{"id":"2Ed2v8j56hCO","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1719274930735,"user_tz":420,"elapsed":227,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"}},"outputId":"0cce7985-9370-4723-de6f-b300391ba055"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-246812ffa83f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSemanticSegmentationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercentage_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"SKX6H6GnpaRB"},"source":["Normalization & Train/Test/Val Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyWjq5-vpcif"},"outputs":[],"source":["# Convert the lists to numpy arrays\n","images = np.array(images, dtype=np.float32)\n","masks = np.array(masks, dtype=np.float32)\n","\n","# Normalize the values\n","images /= 255.0\n","masks /= 255.0\n","masks = masks.reshape((-1, 256, 256, 1))\n","\n","# Split the data into training and test sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=1995)\n","\n","# Further split the training set into training and validation sets (90% train, 10% val)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1995)\n","\n","# If X_train, X_test, X_val have an extra unnecessary dimension at axis=1, remove it:\n","X_train = X_train.squeeze(axis=1)\n","X_test = X_test.squeeze(axis=1)\n","X_val = X_val.squeeze(axis=1)\n","\n","# Display the shapes of the datasets to confirm correct dimensions\n","print('Dataset Shapes:')\n","print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n","print(f'X_val:   {X_val.shape}, y_val: {y_val.shape}')\n","print(f'X_test:  {X_test.shape}, y_test: {y_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"85MNZvtrpuar"},"source":["Metrics & Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRgTuRcepv8d"},"outputs":[],"source":["from sklearn.utils.class_weight import compute_class_weight\n","from keras.callbacks import LearningRateScheduler\n","import matplotlib.pyplot as plt\n","\n","# CUSTOM METRICS\n","\n","# Dice Coefficient: Measures overlap between true and predicted masks.\n","def dice_coefficient(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + tf.keras.backend.epsilon())\n","\n","# Jaccard Index: Measures the ratio of intersection to the union of true and predicted masks.\n","def jaccard_index(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    union = tf.reduce_sum(y_true_f + y_pred_f) - intersection\n","    return (intersection + tf.keras.backend.epsilon()) / (union + tf.keras.backend.epsilon())\n","\n","# Sensitivity: Measures the proportion of actual positives correctly identified.\n","def sensitivity(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    true_positives = tf.reduce_sum(y_true_f * y_pred_f)\n","    possible_positives = tf.reduce_sum(y_true_f)\n","    return true_positives / (possible_positives + tf.keras.backend.epsilon())\n","\n","# Specificity: Measures the proportion of actual negatives correctly identified.\n","def specificity(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    true_negatives = tf.reduce_sum((1-y_true_f) * (1-y_pred_f))\n","    possible_negatives = tf.reduce_sum(1-y_true_f)\n","    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n","\n","# Precision: Measures the proportion of predicted positives that are actually true positives.\n","def precision(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) > threshold, tf.float32)\n","    true_positives = tf.reduce_sum(y_true_f * y_pred_f)\n","    predicted_positives = tf.reduce_sum(y_pred_f)\n","    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","\n","\n","# LOSS FUNCTION\n","def calculate_class_weights(masks):\n","    flat_labels = masks.flatten().astype(int)\n","    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(flat_labels), y=flat_labels)\n","    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","    return class_weights_dict\n","\n","def weighted_binary_crossentropy(weights):\n","    def loss(y_true, y_pred):\n","        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n","        weighted_bce = bce * (weights[1] * y_true + weights[0] * (1 - y_true))\n","        return tf.keras.backend.mean(weighted_bce)\n","    return loss\n","\n","# Calculate the class weights for the training masks\n","class_weights = calculate_class_weights(y_train)\n","print(\"Class weights:\", class_weights)\n","\n","# Visualize class weight distribution\n","plt.bar(class_weights.keys(), class_weights.values())\n","plt.title(\"Class Weight Distribution\")\n","plt.xlabel(\"Class\")\n","plt.ylabel(\"Weight\")\n","plt.show()\n","\n","weighted_loss = weighted_binary_crossentropy(class_weights)"]},{"cell_type":"markdown","metadata":{"id":"JeXtfUcd5I8o"},"source":["Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxguaxwF5HuU"},"outputs":[],"source":["from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import VGG16\n","\n","def vgg16_unet(input_size=(256, 256, 3), freeze_vgg16=True, dropout_rate=0.45):\n","    inputs = Input(input_size)\n","    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n","\n","    if freeze_vgg16:\n","        # Freeze the VGG16 layers\n","        for layer in vgg16.layers:\n","            layer.trainable = False\n","\n","    # Skip connections from VGG16 layers\n","    s1 = vgg16.get_layer(\"block1_conv2\").output\n","    s2 = vgg16.get_layer(\"block2_conv2\").output\n","    s3 = vgg16.get_layer(\"block3_conv3\").output\n","    s4 = vgg16.get_layer(\"block4_conv3\").output\n","    bridge = vgg16.get_layer(\"block5_conv3\").output\n","\n","    # Decoder with dropout\n","    up1 = UpSampling2D((2, 2))(bridge)\n","    up1 = concatenate([up1, s4])\n","    up1 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n","    up1 = Dropout(dropout_rate)(up1)\n","\n","    up2 = UpSampling2D((2, 2))(up1)\n","    up2 = concatenate([up2, s3])\n","    up2 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n","    up2 = Dropout(dropout_rate)(up2)\n","\n","    up3 = UpSampling2D((2, 2))(up2)\n","    up3 = concatenate([up3, s2])\n","    up3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n","    up3 = Dropout(dropout_rate)(up3)\n","\n","    up4 = UpSampling2D((2, 2))(up3)\n","    up4 = concatenate([up4, s1])\n","    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n","    up4 = Dropout(dropout_rate)(up4)\n","\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(up4)\n","\n","    model = Model(inputs, outputs)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"iVA6ln9zp-Ke"},"source":["Model Compilation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOa_BtwAqWNK"},"outputs":[],"source":["from keras.optimizers import SGD\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import BinaryCrossentropy\n","\n","# Define the model\n","model = vgg16_unet()\n","\n","# Compile the model\n","model.compile(\n","    optimizer=Adam(learning_rate=1e-3),\n","    loss=weighted_loss,\n","    metrics=['accuracy', dice_coefficient, jaccard_index, sensitivity, specificity, precision]\n",")\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"9pd10BmVsJJc"},"source":["Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8N1wpf-sKt8"},"outputs":[],"source":["# Early Stopping to prevent overfitting\n","early_stopping = EarlyStopping(\n","    monitor='val_dice_coefficient',\n","    patience=15,\n","    verbose=1,\n","    mode='max',\n","    restore_best_weights=True\n",")\n","\n","model_checkpoint = ModelCheckpoint(\n","    f'/gdrive/My Drive/Dataset/Models/best_{model_name}.h5',  # Path where the model will be saved\n","    monitor='val_dice_coefficient',  # Save the model based on the maximum dice_coefficient value\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n",")\n","\n","# Fit the model\n","history = model.fit(\n","    X_train, y_train,\n","    batch_size=8,\n","    epochs=50,\n","    verbose=1,\n","    validation_data=(X_val, y_val),\n","    callbacks=[model_checkpoint, early_stopping]\n",")\n","\n","# Save the model\n","model.save(f'/gdrive/My Drive/Dataset/Models/{model_name}.h5')\n","print(f'Model saved to: /gdrive/My Drive/Dataset/Models/{model_name}.h5')"]},{"cell_type":"markdown","metadata":{"id":"XpKxuoOXtGOe"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"eEY45m0AsTyF"},"source":["Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3QbrIXpsU9K"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","from sklearn.metrics import roc_auc_score\n","\n","from sklearn.metrics import roc_auc_score\n","\n","# Evaluation functions\n","def plot_training_history(history):\n","    plt.figure(figsize=(12, 6))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Loss Over Epochs')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['dice_coefficient'], label='Training Dice Coefficient')\n","    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coefficient')\n","    plt.title('Dice Coefficient Over Epochs')\n","    plt.legend()\n","\n","    plt.show()\n","\n","def show_predictions(X, y_true, y_pred, threshold=threshold, num_samples=5):\n","    indices = np.random.choice(range(len(X)), num_samples, replace=False)\n","\n","    for i in indices:\n","        plt.figure(figsize=(12, 6))\n","        plt.subplot(1, 3, 1)\n","        plt.imshow(X[i])\n","        plt.title(f'Original Image [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 2)\n","        plt.imshow(y_true[i].squeeze(), cmap='gray')\n","        plt.title(f'True Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 3)\n","        plt.imshow(y_pred[i].squeeze() > threshold, cmap='gray')  # Apply a threshold to convert probabilities to binary mask\n","        plt.title(f'Predicted Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.show()\n","\n","def plot_confusion_matrix(y_true, y_pred, threshold=threshold):\n","    y_true_f = y_true.flatten()\n","    y_pred_f = (y_pred.flatten() > threshold).astype(int)  # Thresholding probabilities\n","\n","    cm = confusion_matrix(y_true_f, y_pred_f)\n","    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the confusion matrix\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","\n","    labels = ['True Negative (Correct: No Buildings)', 'False Positive (Incorrect: There Was No Building)', 'False Negative (Incorrect: There Was A Building Here)', 'True Positive (Correct: There Is A Building Here)']\n","    counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n","    percentages = [\"{0:.2%}\".format(value) for value in cm_normalized.flatten()]\n","\n","    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(labels, counts, percentages)]\n","    labels = np.asarray(labels).reshape(2, 2)\n","\n","    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, center=0)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Perform the evaluation\n","plot_training_history(history)\n","y_pred = model.predict(X_test)\n","show_predictions(X_test, y_test, y_pred, threshold=threshold)\n","plot_confusion_matrix(y_test, y_pred, threshold=threshold)\n","print(classification_report(y_test.flatten(), (y_pred.flatten() > threshold).astype(int)))\n","print(\"ROC-AUC:\", roc_auc_score(y_test.flatten(), y_pred.flatten()))\n"]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_curve, auc\n","\n","# Calculate pr-aUC\n","precision, recall, pr_thresholds = precision_recall_curve(y_test.flatten(), y_pred.flatten())\n","pr_auc = auc(recall, precision)\n","\n","plt.figure(figsize=(8, 6))\n","plt.plot(recall, precision, label='PR-AUC = {:.2f}'.format(pr_auc))\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall Curve')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"AzISsJ3VmlIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kill $(ps aux | awk '{print $2}')"],"metadata":{"id":"bjIfdBSauQf6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1tFMEB-8bfWdfn-cWQs40aL3ibY7xAF3F","timestamp":1718669696876},{"file_id":"1xdkJDhMZSMQDL9DqH2Cfo-SXJ4-fEbn8","timestamp":1717744093026},{"file_id":"1tV46XNdZl_AE63UNatnuDTXY7BLgNm_C","timestamp":1717742309105},{"file_id":"1w6WrZDJzNpil0JeZgEFE6jSg4CSLLQQ4","timestamp":1717632628274},{"file_id":"19DS5qwx75mP-eK27m8oBvT_JI2JAxH46","timestamp":1717632552053},{"file_id":"1-o6MDo9NPK7EaVKJ2VK09v8f8jWNdzDb","timestamp":1717624891008},{"file_id":"13AtxDolagShilgCPs62zvCbdyb5fv6ou","timestamp":1717561655921},{"file_id":"1voqT6cKZytwma8zA0QrtwCX9tUAOvEJ_","timestamp":1717545137189},{"file_id":"11cQTe7Eol_kFXnjSdggg1tPfc_nCMFZO","timestamp":1717425043988},{"file_id":"14p7aFNTaI5ZSsc4Y0w4fcY3l6VKxkkFW","timestamp":1717396481877},{"file_id":"1NpShU9m-Nj2D6tCdSxCff3TpL1Y5aKF6","timestamp":1717380265657},{"file_id":"1f1lIddKXevfi94mJs3PuxBxnuM8uZQwo","timestamp":1717380004583},{"file_id":"15BvoeeprCeA1pk7MPCqg6cTM9JuV7IMU","timestamp":1717229218582},{"file_id":"1xDjMyzCNWDd78z51V5LG7-Fb94tRFS6c","timestamp":1717202269266},{"file_id":"1T0bDS1xnUbpTn_HKo-QW-hpHKzAiC40F","timestamp":1717097791182},{"file_id":"1pYfR623jCKtZ1BkOrjZDqoZh0AaLR1dq","timestamp":1717085451334},{"file_id":"1Gyjx9u2SBZzf4fzcEZ-dytx7j6pCy_Tz","timestamp":1717046772304},{"file_id":"16GmAaRyICYXTTeqUaZFMWUtzqK1Fw_nR","timestamp":1717043481212},{"file_id":"1elMNkk0w4e6W0gWUEr4QE6xtozqkygu9","timestamp":1717011460322}],"authorship_tag":"ABX9TyMb9qx0ir20c7tBs97WWxqe"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}