{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZF6wxhvx+7Xi5I+vRroDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Install/Import Libraries"],"metadata":{"id":"ChgbLgOXpaaN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9oZAIqxpI8g"},"outputs":[],"source":["!pip install torch torchvision\n","!pip install segmentation-models-pytorch"]},{"cell_type":"markdown","source":["Define the model (Pytorch)"],"metadata":{"id":"IpPgyt99pYcO"}},{"cell_type":"code","source":["import torch\n","import segmentation_models_pytorch as smp\n","from torch.utils.data import DataLoader\n","\n","# Define the model\n","model = smp.HRNetV2('W48', classes=1, activation='sigmoid')\n","\n","# Define your dataset\n","class SentinelDataset(torch.utils.data.Dataset):\n","    def __init__(self, images, masks, transforms=None):\n","        self.images = images\n","        self.masks = masks\n","        self.transforms = transforms\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        mask = self.masks[idx]\n","\n","        if self.transforms:\n","            augmented = self.transforms(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask\n","\n","# Instantiate the dataset and dataloader\n","# Here you need to add your actual data and possibly transforms\n","train_dataset = SentinelDataset(train_images, train_masks)\n","train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n","\n","# Define the loss function and optimizer\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    for images, masks in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, masks)\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"],"metadata":{"id":"eabJnYO1pOXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, UpSampling2D, Concatenate\n","\n","def conv_block(input_tensor, num_filters, kernel_size=3, strides=1):\n","    x = Conv2D(num_filters, (kernel_size, kernel_size), strides=strides, padding=\"same\")(input_tensor)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","def high_resolution_module(input_tensor, num_filters):\n","    # High Resolution Branch\n","    hr_branch = conv_block(input_tensor, num_filters)\n","\n","    # Low Resolution Branch\n","    lr_branch = conv_block(input_tensor, num_filters, strides=2)\n","    lr_branch = conv_block(lr_branch, num_filters)\n","    lr_branch = UpSampling2D()(lr_branch)  # Upsampling to match the high-resolution branch size\n","\n","    # Combining branches\n","    out = Add()([hr_branch, lr_branch])\n","    return out\n","\n","def create_hrnet(input_shape, num_classes):\n","    inputs = Input(input_shape)\n","\n","    x = conv_block(inputs, 64)  # Initial convolution\n","    for _ in range(3):  # Adding multiple HR modules\n","        x = high_resolution_module(x, 128)\n","\n","    # Classifier head\n","    outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)  # Using sigmoid for binary classification\n","\n","    model = Model(inputs, outputs)\n","    return model\n","\n","# Model instantiation for a 256x256 input image with 3 channels (RGB)\n","model = create_hrnet((256, 256, 3), 1)\n","model.summary()\n"],"metadata":{"id":"2rJrguKtUI8I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"mfCk_5sYUtOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming `train_images` and `train_masks` are your training data and labels\n","history = model.fit(train_images, train_masks, epochs=10, batch_size=16, validation_split=0.2)\n"],"metadata":{"id":"xnJ1PUWCUwE5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["https://chat.openai.com/c/723f58c5-d395-45fa-a8b7-9e152a933dfc"],"metadata":{"id":"cGUuLYt6Ux7l"},"execution_count":null,"outputs":[]}]}