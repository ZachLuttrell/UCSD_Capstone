{"cells":[{"cell_type":"markdown","metadata":{"id":"6z4CZeVOowB4"},"source":["# MEViT\n","\n","This is the 10th iteration of MEViT.\n","\n","In this iteration I have included the following changes:\n","\n","- increased learning rate from .001 to .01\n","\n","\n","\n","**NOTE:** Connect to a High-RAM Environment"]},{"cell_type":"markdown","metadata":{"id":"szU0egT7tBFP"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"5mU7Z6Bm3MWK"},"source":["Settings"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717380356368,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"},"user_tz":420},"id":"-7ruruAJ3Noc","outputId":"786ae952-e301-40e9-89e7-a71ed9de3350"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model Name: mevit_model_10\n","Percentage to Load: 50.0%\n","Threshold: 0.5\n","Scale Factor: 2.0\n"]}],"source":["# MODEL SETTINGS\n","model_name = 'mevit_model_10'\n","percentage_to_load = 50 / 100.0  # Set the % of dataset to be loaded here.\n","threshold = 0.5  # Set the threshold for metrics here\n","scale_factor = 2.0  # Factor by which to scale images and masks\n","print(f'Model Name: {model_name}')\n","print(f'Percentage to Load: {percentage_to_load*100}%')\n","print(f'Threshold: {threshold}')\n","print(f'Scale Factor: {scale_factor}')"]},{"cell_type":"markdown","metadata":{"id":"8nAk5_E-pMPE"},"source":["Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34032,"status":"ok","timestamp":1717380390396,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"},"user_tz":420},"id":"YgBD9gDcovEY","outputId":"b07b9ecb-da1b-4322-9240-15605f77dcd7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /gdrive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/gdrive')\n","\n","# Imports\n","import os\n","import cv2\n","import numpy as np\n","import tifffile as tiff\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import LayerNormalization, Dense, Dropout, Flatten, Conv2DTranspose\n","from tensorflow.keras.models import Model\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm"]},{"cell_type":"markdown","metadata":{"id":"0Kt6_4oqpOKr"},"source":["Data Loading"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161884,"status":"ok","timestamp":1717381573421,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"},"user_tz":420},"id":"7SO8PR--pASc","outputId":"b561dbda-4fb0-415c-e19b-bdfedc3dea2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of image files: 4787\n","Number of mask files: 4787\n","Attempting to load 50.0% of dataset: 2393 images/mask pairs...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2393/2393 [19:00\u003c00:00,  2.10it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Loading complete.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Function to count files\n","def count_files(directory, extension=\".tif\"):\n","    return sum(1 for file in os.listdir(directory) if file.endswith(extension))\n","\n","# Paths to your image and mask directories\n","image_directory = '/gdrive/My Drive/Dataset/patches/train/images/'\n","mask_directory = '/gdrive/My Drive/Dataset/patches/train/masks/'\n","\n","# Counting the TIFF files in both directories\n","image_count = count_files(image_directory)\n","mask_count = count_files(mask_directory)\n","\n","print(f\"Number of image files: {image_count}\")\n","print(f\"Number of mask files: {mask_count}\")\n","\n","# Load the images and masks into the lists below\n","images = []\n","masks = []\n","\n","# Sort filenames to ensure matching pairs align\n","image_files = sorted([f for f in os.listdir(image_directory) if f.endswith(\".tif\")])\n","mask_files = sorted([f for f in os.listdir(mask_directory) if f.endswith(\".tif\")])\n","\n","# Determine how many files to load based on percentage\n","number_of_files_to_load = int(len(image_files) * percentage_to_load)\n","\n","# Create a mapping of image names to their corresponding mask names by removing '_Buildings'\n","image_to_mask = {f: f.replace(\"_patch\", \"_Buildings_patch\") for f in image_files}\n","\n","# Only iterate over the subset of files determined by the percentage\n","print(f'Attempting to load {percentage_to_load*100}% of dataset: {number_of_files_to_load} images/mask pairs...')\n","for count, image_name in enumerate(tqdm(image_files[:number_of_files_to_load]), start=1):\n","    try:\n","        img_path = os.path.join(image_directory, image_name)\n","        mask_name = image_to_mask[image_name]\n","        mask_path = os.path.join(mask_directory, mask_name)\n","\n","        if os.path.exists(mask_path):\n","            img = tiff.imread(img_path)\n","            mask = tiff.imread(mask_path)\n","\n","            images.append(img)\n","            masks.append(mask)\n","        else:\n","            print(f'\\nMask not found for image: {image_name}')\n","    except Exception as e:\n","        print(f'\\nError loading image/mask pair {image_name}: {e}')\n","\n","print(\"\\nLoading complete.\")\n","\n","# Check if the number of images and masks loaded are equal\n","if len(images) != len(masks):\n","    raise ValueError(\"The number of loaded images and masks do not match!\")"]},{"cell_type":"markdown","metadata":{"id":"SKX6H6GnpaRB"},"source":["Normalization \u0026 Train/Test/Val Split"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7324,"status":"ok","timestamp":1717381580743,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"},"user_tz":420},"id":"XyWjq5-vpcif","outputId":"a1dbee23-340a-4810-f716-57df89099ab7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original image shape: (2393, 256, 256, 3)\n","New size: (512, 512)\n","Resizing images and masks...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2393/2393 [00:02\u003c00:00, 1030.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Dataset Shapes:\n","X_train: (1722, 512, 512, 3), y_train: (1722, 512, 512, 1)\n","X_val:   (192, 512, 512, 3), y_val: (192, 512, 512, 1)\n","X_test:  (479, 512, 512, 3), y_test: (479, 512, 512, 1)\n"]}],"source":["# Function to resize and normalize images and masks\n","def preprocess_images_and_masks(images, masks, scale_factor):\n","    # Squeeze unnecessary singleton dimensions\n","    if images.ndim \u003e 3 and images.shape[1] == 1:\n","        images = images.squeeze(axis=1)\n","    if masks.ndim \u003e 3 and masks.shape[1] == 1:\n","        masks = masks.squeeze(axis=1)\n","\n","    print(f\"Original image shape: {images.shape}\")\n","    new_size = (int(images.shape[1] * scale_factor), int(images.shape[2] * scale_factor))\n","    print(f\"New size: {new_size}\")\n","\n","    if new_size[0] \u003c= 0 or new_size[1] \u003c= 0:\n","        raise ValueError(\"Scale factor resulted in invalid size. Check the scale factor and original dimensions.\")\n","\n","    resized_images = []\n","    resized_masks = []\n","    print(\"Resizing images and masks...\")\n","    for img, mask in tqdm(zip(images, masks), total=len(images)):\n","\n","        try:\n","            resized_img = cv2.resize(img, new_size)\n","            resized_mask = cv2.resize(mask, new_size, interpolation=cv2.INTER_NEAREST)\n","            resized_images.append(resized_img)\n","            resized_masks.append(resized_mask)\n","        except Exception as e:\n","            print(f\"Error resizing image/mask pair: {e}\")\n","            raise\n","\n","    resized_images = np.array(resized_images, dtype=np.float32)\n","    resized_masks = np.array(resized_masks, dtype=np.float32)\n","\n","    # Normalize images and masks\n","    resized_images /= 255.0\n","    resized_masks /= 255.0\n","    resized_masks = resized_masks.reshape((-1, new_size[0], new_size[1], 1))\n","\n","    return resized_images, resized_masks\n","\n","# Convert the lists to numpy arrays\n","images = np.array(images, dtype=np.float32)\n","masks = np.array(masks, dtype=np.float32)\n","\n","# Resize and normalize images and masks\n","images, masks = preprocess_images_and_masks(images, masks, scale_factor)\n","\n","# Split the data into training and test sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=1995)\n","\n","# Further split the training set into training and validation sets (90% train, 10% val)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1995)\n","\n","# Display the shapes of the datasets to confirm correct dimensions\n","print('Dataset Shapes:')\n","print(f'X_train: {X_train.shape}, y_train: {y_train.shape}')\n","print(f'X_val:   {X_val.shape}, y_val: {y_val.shape}')\n","print(f'X_test:  {X_test.shape}, y_test: {y_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"85MNZvtrpuar"},"source":["Metrics \u0026 Loss"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"elapsed":50730,"status":"ok","timestamp":1717381631471,"user":{"displayName":"Zachary Luttrell","userId":"00155576860657313600"},"user_tz":420},"id":"MRgTuRcepv8d","outputId":"16777ac6-e8d1-4020-b04e-2b4068a2acdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class weights: {0: 0.5339968946194886, 1: 7.853612816644959}\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 640x480 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.utils.class_weight import compute_class_weight\n","from keras.callbacks import LearningRateScheduler\n","import matplotlib.pyplot as plt\n","\n","# Custom Metrics\n","def dice_coefficient(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) \u003e threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + tf.keras.backend.epsilon())\n","\n","def jaccard_index(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) \u003e threshold, tf.float32)\n","    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n","    union = tf.reduce_sum(y_true_f + y_pred_f) - intersection\n","    return (intersection + tf.keras.backend.epsilon()) / (union + tf.keras.backend.epsilon())\n","\n","def sensitivity(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) \u003e threshold, tf.float32)\n","    true_positives = tf.reduce_sum(y_true_f * y_pred_f)\n","    possible_positives = tf.reduce_sum(y_true_f)\n","    return true_positives / (possible_positives + tf.keras.backend.epsilon())\n","\n","def specificity(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) \u003e threshold, tf.float32)\n","    true_negatives = tf.reduce_sum((1-y_true_f) * (1-y_pred_f))\n","    possible_negatives = tf.reduce_sum(1-y_true_f)\n","    return true_negatives / (possible_negatives + tf.keras.backend.epsilon())\n","\n","def precision(y_true, y_pred, threshold=threshold):\n","    y_true_f = tf.reshape(y_true, [-1])\n","    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]) \u003e threshold, tf.float32)\n","    true_positives = tf.reduce_sum(y_true_f * y_pred_f)\n","    predicted_positives = tf.reduce_sum(y_pred_f)\n","    return true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","\n","# Loss Function\n","def calculate_class_weights(masks):\n","    flat_labels = masks.flatten().astype(int)\n","    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(flat_labels), y=flat_labels)\n","    class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","    return class_weights_dict\n","\n","def weighted_binary_crossentropy(weights):\n","    def loss(y_true, y_pred):\n","        bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)\n","        weighted_bce = bce * (weights[1] * y_true + weights[0] * (1 - y_true))\n","        return tf.keras.backend.mean(weighted_bce)\n","    return loss\n","\n","# Calculate the class weights for the training masks\n","class_weights = calculate_class_weights(y_train)\n","print(\"Class weights:\", class_weights)\n","\n","# Visualize class weight distribution\n","plt.bar(class_weights.keys(), class_weights.values())\n","plt.title(\"Class Weight Distribution\")\n","plt.xlabel(\"Class\")\n","plt.ylabel(\"Weight\")\n","plt.show()\n","\n","weighted_loss = weighted_binary_crossentropy(class_weights)"]},{"cell_type":"markdown","metadata":{"id":"JeXtfUcd5I8o"},"source":["Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxguaxwF5HuU"},"outputs":[],"source":["# Define the MEViT model\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.ffn = models.Sequential([\n","            layers.Dense(ff_dim, activation='relu'),\n","            layers.Dense(embed_dim),\n","        ])\n","        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","def create_vit_segmentation_model(input_shape, num_classes, embed_dim, num_heads, ff_dim):\n","    inputs = layers.Input(shape=input_shape)\n","    # Flatten the input\n","    x = layers.Reshape((-1, input_shape[-1]))(inputs)\n","\n","    # Create patches and embed\n","    patch_size = 16  # Adjust as necessary based on image size and memory constraints\n","    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n","    patches = layers.Conv2D(filters=embed_dim, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(inputs)\n","    patches = layers.Reshape((num_patches, embed_dim))(patches)\n","\n","    # Add Transformer blocks\n","    for _ in range(8):\n","        patches = TransformerBlock(embed_dim, num_heads, ff_dim)(patches)\n","\n","    # Reshape back to image\n","    x = layers.Reshape((input_shape[0] // patch_size, input_shape[1] // patch_size, embed_dim))(patches)\n","    x = Conv2DTranspose(num_classes, kernel_size=patch_size, strides=patch_size, padding=\"valid\")(x)\n","    outputs = layers.Activation('sigmoid')(x)\n","\n","    return Model(inputs, outputs)"]},{"cell_type":"markdown","metadata":{"id":"iVA6ln9zp-Ke"},"source":["Model Compilation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOa_BtwAqWNK"},"outputs":[],"source":["from keras.optimizers import SGD\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","input_shape = (int(256 * scale_factor), int(256 * scale_factor), 3)\n","num_classes = 1\n","embed_dim = 64  # Adjust as necessary\n","num_heads = 4   # Adjust as necessary\n","ff_dim = 128    # Adjust as necessary\n","\n","model = create_vit_segmentation_model(input_shape, num_classes, embed_dim, num_heads, ff_dim)\n","model._name = model_name\n","model.summary()\n","\n","# Learning rate schedule\n","def lr_schedule(epoch, lr):\n","    if epoch \u003e= 50 and epoch \u003c 100:\n","        return lr * 0.99\n","    elif epoch \u003e= 100 and epoch \u003c 125:\n","        return lr * 0.9\n","    return lr\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","# Compile the model\n","initial_lr = 0.01  # Start with a lower initial learning rate\n","sgd = SGD(learning_rate=initial_lr, momentum=0.9)\n","model.compile(\n","    optimizer=sgd,\n","    loss=weighted_loss,\n","    metrics=['accuracy', dice_coefficient, jaccard_index, sensitivity, specificity, precision]\n",")"]},{"cell_type":"markdown","metadata":{"id":"9pd10BmVsJJc"},"source":["Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"k8N1wpf-sKt8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.4691 - dice_coefficient: 0.1164 - jaccard_index: 0.0620 - sensitivity: 0.5528 - specificity: 0.4640 - precision: 0.0662\n","Epoch 1: val_dice_coefficient improved from -inf to 0.11988, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 708s 6s/step - loss: 0.6931 - accuracy: 0.4691 - dice_coefficient: 0.1164 - jaccard_index: 0.0620 - sensitivity: 0.5528 - specificity: 0.4640 - precision: 0.0662 - val_loss: 0.6812 - val_accuracy: 0.5776 - val_dice_coefficient: 0.1199 - val_jaccard_index: 0.0639 - val_sensitivity: 0.4671 - val_specificity: 0.5848 - val_precision: 0.0691 - lr: 0.0100\n","Epoch 2/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.5719 - dice_coefficient: 0.1505 - jaccard_index: 0.0818 - sensitivity: 0.5967 - specificity: 0.5699 - precision: 0.0882\n","Epoch 2: val_dice_coefficient improved from 0.11988 to 0.16367, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 719s 7s/step - loss: 0.6836 - accuracy: 0.5719 - dice_coefficient: 0.1505 - jaccard_index: 0.0818 - sensitivity: 0.5967 - specificity: 0.5699 - precision: 0.0882 - val_loss: 0.6623 - val_accuracy: 0.4987 - val_dice_coefficient: 0.1637 - val_jaccard_index: 0.0894 - val_sensitivity: 0.7924 - val_specificity: 0.4794 - val_precision: 0.0917 - lr: 0.0100\n","Epoch 3/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.5971 - dice_coefficient: 0.1796 - jaccard_index: 0.0996 - sensitivity: 0.6549 - specificity: 0.5938 - precision: 0.1179\n","Epoch 3: val_dice_coefficient improved from 0.16367 to 0.18551, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 745s 7s/step - loss: 0.6684 - accuracy: 0.5971 - dice_coefficient: 0.1796 - jaccard_index: 0.0996 - sensitivity: 0.6549 - specificity: 0.5938 - precision: 0.1179 - val_loss: 0.6468 - val_accuracy: 0.6856 - val_dice_coefficient: 0.1855 - val_jaccard_index: 0.1025 - val_sensitivity: 0.5799 - val_specificity: 0.6926 - val_precision: 0.1111 - lr: 0.0100\n","Epoch 4/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.6080 - dice_coefficient: 0.1897 - jaccard_index: 0.1057 - sensitivity: 0.6971 - specificity: 0.6012 - precision: 0.1138\n","Epoch 4: val_dice_coefficient did not improve from 0.18551\n","108/108 [==============================] - 745s 7s/step - loss: 0.6491 - accuracy: 0.6080 - dice_coefficient: 0.1897 - jaccard_index: 0.1057 - sensitivity: 0.6971 - specificity: 0.6012 - precision: 0.1138 - val_loss: 0.6306 - val_accuracy: 0.4800 - val_dice_coefficient: 0.1686 - val_jaccard_index: 0.0924 - val_sensitivity: 0.8557 - val_specificity: 0.4553 - val_precision: 0.0939 - lr: 0.0100\n","Epoch 5/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.6339 - dice_coefficient: 0.2011 - jaccard_index: 0.1124 - sensitivity: 0.7100 - specificity: 0.6282 - precision: 0.1198\n","Epoch 5: val_dice_coefficient did not improve from 0.18551\n","108/108 [==============================] - 722s 7s/step - loss: 0.6295 - accuracy: 0.6339 - dice_coefficient: 0.2011 - jaccard_index: 0.1124 - sensitivity: 0.7100 - specificity: 0.6282 - precision: 0.1198 - val_loss: 0.6259 - val_accuracy: 0.4434 - val_dice_coefficient: 0.1651 - val_jaccard_index: 0.0902 - val_sensitivity: 0.8943 - val_specificity: 0.4138 - val_precision: 0.0913 - lr: 0.0100\n","Epoch 6/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6206 - accuracy: 0.6346 - dice_coefficient: 0.2050 - jaccard_index: 0.1152 - sensitivity: 0.7124 - specificity: 0.6297 - precision: 0.1242\n","Epoch 6: val_dice_coefficient improved from 0.18551 to 0.19852, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 754s 7s/step - loss: 0.6206 - accuracy: 0.6346 - dice_coefficient: 0.2050 - jaccard_index: 0.1152 - sensitivity: 0.7124 - specificity: 0.6297 - precision: 0.1242 - val_loss: 0.6034 - val_accuracy: 0.6674 - val_dice_coefficient: 0.1985 - val_jaccard_index: 0.1104 - val_sensitivity: 0.6724 - val_specificity: 0.6675 - val_precision: 0.1172 - lr: 0.0100\n","Epoch 7/150\n","108/108 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.6460 - dice_coefficient: 0.2086 - jaccard_index: 0.1172 - sensitivity: 0.7206 - specificity: 0.6408 - precision: 0.1241\n","Epoch 7: val_dice_coefficient did not improve from 0.19852\n","108/108 [==============================] - 738s 7s/step - loss: 0.6080 - accuracy: 0.6460 - dice_coefficient: 0.2086 - jaccard_index: 0.1172 - sensitivity: 0.7206 - specificity: 0.6408 - precision: 0.1241 - val_loss: 0.5969 - val_accuracy: 0.6208 - val_dice_coefficient: 0.1949 - val_jaccard_index: 0.1082 - val_sensitivity: 0.7475 - val_specificity: 0.6129 - val_precision: 0.1127 - lr: 0.0100\n","Epoch 8/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5982 - accuracy: 0.6541 - dice_coefficient: 0.2132 - jaccard_index: 0.1200 - sensitivity: 0.7290 - specificity: 0.6485 - precision: 0.1265\n","Epoch 8: val_dice_coefficient did not improve from 0.19852\n","108/108 [==============================] - 758s 7s/step - loss: 0.5982 - accuracy: 0.6541 - dice_coefficient: 0.2132 - jaccard_index: 0.1200 - sensitivity: 0.7290 - specificity: 0.6485 - precision: 0.1265 - val_loss: 0.5895 - val_accuracy: 0.5912 - val_dice_coefficient: 0.1944 - val_jaccard_index: 0.1079 - val_sensitivity: 0.8018 - val_specificity: 0.5777 - val_precision: 0.1111 - lr: 0.0100\n","Epoch 9/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.6557 - dice_coefficient: 0.2139 - jaccard_index: 0.1204 - sensitivity: 0.7310 - specificity: 0.6507 - precision: 0.1268\n","Epoch 9: val_dice_coefficient improved from 0.19852 to 0.22700, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 640s 6s/step - loss: 0.5918 - accuracy: 0.6557 - dice_coefficient: 0.2139 - jaccard_index: 0.1204 - sensitivity: 0.7310 - specificity: 0.6507 - precision: 0.1268 - val_loss: 0.6041 - val_accuracy: 0.7818 - val_dice_coefficient: 0.2270 - val_jaccard_index: 0.1284 - val_sensitivity: 0.5291 - val_specificity: 0.7991 - val_precision: 0.1461 - lr: 0.0100\n","Epoch 10/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5924 - accuracy: 0.6616 - dice_coefficient: 0.2177 - jaccard_index: 0.1228 - sensitivity: 0.7201 - specificity: 0.6577 - precision: 0.1308\n","Epoch 10: val_dice_coefficient did not improve from 0.22700\n","108/108 [==============================] - 617s 6s/step - loss: 0.5924 - accuracy: 0.6616 - dice_coefficient: 0.2177 - jaccard_index: 0.1228 - sensitivity: 0.7201 - specificity: 0.6577 - precision: 0.1308 - val_loss: 0.5796 - val_accuracy: 0.6613 - val_dice_coefficient: 0.2080 - val_jaccard_index: 0.1165 - val_sensitivity: 0.7229 - val_specificity: 0.6577 - val_precision: 0.1223 - lr: 0.0100\n","Epoch 11/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5862 - accuracy: 0.6645 - dice_coefficient: 0.2190 - jaccard_index: 0.1236 - sensitivity: 0.7272 - specificity: 0.6602 - precision: 0.1311\n","Epoch 11: val_dice_coefficient did not improve from 0.22700\n","108/108 [==============================] - 611s 6s/step - loss: 0.5862 - accuracy: 0.6645 - dice_coefficient: 0.2190 - jaccard_index: 0.1236 - sensitivity: 0.7272 - specificity: 0.6602 - precision: 0.1311 - val_loss: 0.5747 - val_accuracy: 0.6699 - val_dice_coefficient: 0.2084 - val_jaccard_index: 0.1166 - val_sensitivity: 0.7105 - val_specificity: 0.6678 - val_precision: 0.1229 - lr: 0.0100\n","Epoch 12/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.6767 - dice_coefficient: 0.2234 - jaccard_index: 0.1265 - sensitivity: 0.7187 - specificity: 0.6731 - precision: 0.1346\n","Epoch 12: val_dice_coefficient did not improve from 0.22700\n","108/108 [==============================] - 612s 6s/step - loss: 0.5814 - accuracy: 0.6767 - dice_coefficient: 0.2234 - jaccard_index: 0.1265 - sensitivity: 0.7187 - specificity: 0.6731 - precision: 0.1346 - val_loss: 0.5722 - val_accuracy: 0.6890 - val_dice_coefficient: 0.2120 - val_jaccard_index: 0.1189 - val_sensitivity: 0.6841 - val_specificity: 0.6900 - val_precision: 0.1263 - lr: 0.0100\n","Epoch 13/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.6672 - dice_coefficient: 0.2191 - jaccard_index: 0.1238 - sensitivity: 0.7201 - specificity: 0.6624 - precision: 0.1316\n","Epoch 13: val_dice_coefficient did not improve from 0.22700\n","108/108 [==============================] - 660s 6s/step - loss: 0.5818 - accuracy: 0.6672 - dice_coefficient: 0.2191 - jaccard_index: 0.1238 - sensitivity: 0.7201 - specificity: 0.6624 - precision: 0.1316 - val_loss: 0.5729 - val_accuracy: 0.5793 - val_dice_coefficient: 0.1975 - val_jaccard_index: 0.1100 - val_sensitivity: 0.8382 - val_specificity: 0.5624 - val_precision: 0.1125 - lr: 0.0100\n","Epoch 14/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5790 - accuracy: 0.6723 - dice_coefficient: 0.2212 - jaccard_index: 0.1250 - sensitivity: 0.7204 - specificity: 0.6688 - precision: 0.1334\n","Epoch 14: val_dice_coefficient improved from 0.22700 to 0.23089, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 799s 7s/step - loss: 0.5790 - accuracy: 0.6723 - dice_coefficient: 0.2212 - jaccard_index: 0.1250 - sensitivity: 0.7204 - specificity: 0.6688 - precision: 0.1334 - val_loss: 0.5775 - val_accuracy: 0.7654 - val_dice_coefficient: 0.2309 - val_jaccard_index: 0.1309 - val_sensitivity: 0.5807 - val_specificity: 0.7782 - val_precision: 0.1455 - lr: 0.0100\n","Epoch 15/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5783 - accuracy: 0.6775 - dice_coefficient: 0.2205 - jaccard_index: 0.1245 - sensitivity: 0.7128 - specificity: 0.6745 - precision: 0.1327\n","Epoch 15: val_dice_coefficient did not improve from 0.23089\n","108/108 [==============================] - 666s 6s/step - loss: 0.5783 - accuracy: 0.6775 - dice_coefficient: 0.2205 - jaccard_index: 0.1245 - sensitivity: 0.7128 - specificity: 0.6745 - precision: 0.1327 - val_loss: 0.5663 - val_accuracy: 0.6846 - val_dice_coefficient: 0.2168 - val_jaccard_index: 0.1220 - val_sensitivity: 0.7086 - val_specificity: 0.6835 - val_precision: 0.1289 - lr: 0.0100\n","Epoch 16/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5705 - accuracy: 0.6726 - dice_coefficient: 0.2232 - jaccard_index: 0.1263 - sensitivity: 0.7344 - specificity: 0.6678 - precision: 0.1334\n","Epoch 16: val_dice_coefficient did not improve from 0.23089\n","108/108 [==============================] - 710s 7s/step - loss: 0.5705 - accuracy: 0.6726 - dice_coefficient: 0.2232 - jaccard_index: 0.1263 - sensitivity: 0.7344 - specificity: 0.6678 - precision: 0.1334 - val_loss: 0.5583 - val_accuracy: 0.6849 - val_dice_coefficient: 0.2184 - val_jaccard_index: 0.1230 - val_sensitivity: 0.7153 - val_specificity: 0.6834 - val_precision: 0.1298 - lr: 0.0100\n","Epoch 17/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.6688 - dice_coefficient: 0.2215 - jaccard_index: 0.1254 - sensitivity: 0.7327 - specificity: 0.6636 - precision: 0.1324\n","Epoch 17: val_dice_coefficient did not improve from 0.23089\n","108/108 [==============================] - 705s 7s/step - loss: 0.5669 - accuracy: 0.6688 - dice_coefficient: 0.2215 - jaccard_index: 0.1254 - sensitivity: 0.7327 - specificity: 0.6636 - precision: 0.1324 - val_loss: 0.5570 - val_accuracy: 0.6915 - val_dice_coefficient: 0.2197 - val_jaccard_index: 0.1237 - val_sensitivity: 0.7139 - val_specificity: 0.6906 - val_precision: 0.1307 - lr: 0.0100\n","Epoch 18/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5674 - accuracy: 0.6799 - dice_coefficient: 0.2249 - jaccard_index: 0.1275 - sensitivity: 0.7247 - specificity: 0.6764 - precision: 0.1351\n","Epoch 18: val_dice_coefficient improved from 0.23089 to 0.23109, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 759s 7s/step - loss: 0.5674 - accuracy: 0.6799 - dice_coefficient: 0.2249 - jaccard_index: 0.1275 - sensitivity: 0.7247 - specificity: 0.6764 - precision: 0.1351 - val_loss: 0.5628 - val_accuracy: 0.7446 - val_dice_coefficient: 0.2311 - val_jaccard_index: 0.1310 - val_sensitivity: 0.6321 - val_specificity: 0.7527 - val_precision: 0.1427 - lr: 0.0100\n","Epoch 19/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.6735 - dice_coefficient: 0.2257 - jaccard_index: 0.1279 - sensitivity: 0.7314 - specificity: 0.6690 - precision: 0.1355\n","Epoch 19: val_dice_coefficient did not improve from 0.23109\n","108/108 [==============================] - 752s 7s/step - loss: 0.5679 - accuracy: 0.6735 - dice_coefficient: 0.2257 - jaccard_index: 0.1279 - sensitivity: 0.7314 - specificity: 0.6690 - precision: 0.1355 - val_loss: 0.5504 - val_accuracy: 0.6490 - val_dice_coefficient: 0.2144 - val_jaccard_index: 0.1205 - val_sensitivity: 0.7759 - val_specificity: 0.6410 - val_precision: 0.1251 - lr: 0.0100\n","Epoch 20/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.6675 - dice_coefficient: 0.2237 - jaccard_index: 0.1268 - sensitivity: 0.7405 - specificity: 0.6609 - precision: 0.1340\n","Epoch 20: val_dice_coefficient did not improve from 0.23109\n","108/108 [==============================] - 886s 8s/step - loss: 0.5646 - accuracy: 0.6675 - dice_coefficient: 0.2237 - jaccard_index: 0.1268 - sensitivity: 0.7405 - specificity: 0.6609 - precision: 0.1340 - val_loss: 0.5558 - val_accuracy: 0.6565 - val_dice_coefficient: 0.2109 - val_jaccard_index: 0.1182 - val_sensitivity: 0.7531 - val_specificity: 0.6506 - val_precision: 0.1234 - lr: 0.0100\n","Epoch 21/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.6833 - dice_coefficient: 0.2273 - jaccard_index: 0.1290 - sensitivity: 0.7204 - specificity: 0.6805 - precision: 0.1373\n","Epoch 21: val_dice_coefficient did not improve from 0.23109\n","108/108 [==============================] - 736s 7s/step - loss: 0.5686 - accuracy: 0.6833 - dice_coefficient: 0.2273 - jaccard_index: 0.1290 - sensitivity: 0.7204 - specificity: 0.6805 - precision: 0.1373 - val_loss: 0.5661 - val_accuracy: 0.7327 - val_dice_coefficient: 0.2284 - val_jaccard_index: 0.1293 - val_sensitivity: 0.6494 - val_specificity: 0.7387 - val_precision: 0.1398 - lr: 0.0100\n","Epoch 22/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.6802 - dice_coefficient: 0.2291 - jaccard_index: 0.1300 - sensitivity: 0.7420 - specificity: 0.6754 - precision: 0.1366\n","Epoch 22: val_dice_coefficient did not improve from 0.23109\n","108/108 [==============================] - 700s 6s/step - loss: 0.5559 - accuracy: 0.6802 - dice_coefficient: 0.2291 - jaccard_index: 0.1300 - sensitivity: 0.7420 - specificity: 0.6754 - precision: 0.1366 - val_loss: 0.5402 - val_accuracy: 0.6687 - val_dice_coefficient: 0.2226 - val_jaccard_index: 0.1256 - val_sensitivity: 0.7728 - val_specificity: 0.6622 - val_precision: 0.1308 - lr: 0.0100\n","Epoch 23/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5574 - accuracy: 0.6782 - dice_coefficient: 0.2282 - jaccard_index: 0.1296 - sensitivity: 0.7382 - specificity: 0.6725 - precision: 0.1368\n","Epoch 23: val_dice_coefficient did not improve from 0.23109\n","108/108 [==============================] - 757s 7s/step - loss: 0.5574 - accuracy: 0.6782 - dice_coefficient: 0.2282 - jaccard_index: 0.1296 - sensitivity: 0.7382 - specificity: 0.6725 - precision: 0.1368 - val_loss: 0.5535 - val_accuracy: 0.7105 - val_dice_coefficient: 0.2234 - val_jaccard_index: 0.1262 - val_sensitivity: 0.6767 - val_specificity: 0.7132 - val_precision: 0.1348 - lr: 0.0100\n","Epoch 24/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.6775 - dice_coefficient: 0.2290 - jaccard_index: 0.1301 - sensitivity: 0.7358 - specificity: 0.6735 - precision: 0.1380\n","Epoch 24: val_dice_coefficient improved from 0.23109 to 0.23218, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 810s 8s/step - loss: 0.5606 - accuracy: 0.6775 - dice_coefficient: 0.2290 - jaccard_index: 0.1301 - sensitivity: 0.7358 - specificity: 0.6735 - precision: 0.1380 - val_loss: 0.5411 - val_accuracy: 0.7042 - val_dice_coefficient: 0.2322 - val_jaccard_index: 0.1317 - val_sensitivity: 0.7297 - val_specificity: 0.7029 - val_precision: 0.1389 - lr: 0.0100\n","Epoch 25/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.6908 - dice_coefficient: 0.2349 - jaccard_index: 0.1338 - sensitivity: 0.7466 - specificity: 0.6868 - precision: 0.1408\n","Epoch 25: val_dice_coefficient improved from 0.23218 to 0.25362, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 879s 8s/step - loss: 0.5485 - accuracy: 0.6908 - dice_coefficient: 0.2349 - jaccard_index: 0.1338 - sensitivity: 0.7466 - specificity: 0.6868 - precision: 0.1408 - val_loss: 0.5364 - val_accuracy: 0.7622 - val_dice_coefficient: 0.2536 - val_jaccard_index: 0.1456 - val_sensitivity: 0.6634 - val_specificity: 0.7692 - val_precision: 0.1582 - lr: 0.0100\n","Epoch 26/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5442 - accuracy: 0.6963 - dice_coefficient: 0.2401 - jaccard_index: 0.1372 - sensitivity: 0.7469 - specificity: 0.6918 - precision: 0.1449\n","Epoch 26: val_dice_coefficient did not improve from 0.25362\n","108/108 [==============================] - 665s 6s/step - loss: 0.5442 - accuracy: 0.6963 - dice_coefficient: 0.2401 - jaccard_index: 0.1372 - sensitivity: 0.7469 - specificity: 0.6918 - precision: 0.1449 - val_loss: 0.5288 - val_accuracy: 0.6369 - val_dice_coefficient: 0.2188 - val_jaccard_index: 0.1233 - val_sensitivity: 0.8218 - val_specificity: 0.6248 - val_precision: 0.1268 - lr: 0.0100\n","Epoch 27/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5464 - accuracy: 0.6843 - dice_coefficient: 0.2356 - jaccard_index: 0.1341 - sensitivity: 0.7548 - specificity: 0.6789 - precision: 0.1409\n","Epoch 27: val_dice_coefficient improved from 0.25362 to 0.26125, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 659s 6s/step - loss: 0.5464 - accuracy: 0.6843 - dice_coefficient: 0.2356 - jaccard_index: 0.1341 - sensitivity: 0.7548 - specificity: 0.6789 - precision: 0.1409 - val_loss: 0.5459 - val_accuracy: 0.7842 - val_dice_coefficient: 0.2613 - val_jaccard_index: 0.1506 - val_sensitivity: 0.6249 - val_specificity: 0.7951 - val_precision: 0.1667 - lr: 0.0100\n","Epoch 28/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.6948 - dice_coefficient: 0.2402 - jaccard_index: 0.1372 - sensitivity: 0.7558 - specificity: 0.6902 - precision: 0.1443\n","Epoch 28: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 696s 6s/step - loss: 0.5429 - accuracy: 0.6948 - dice_coefficient: 0.2402 - jaccard_index: 0.1372 - sensitivity: 0.7558 - specificity: 0.6902 - precision: 0.1443 - val_loss: 0.5218 - val_accuracy: 0.7266 - val_dice_coefficient: 0.2472 - val_jaccard_index: 0.1414 - val_sensitivity: 0.7352 - val_specificity: 0.7262 - val_precision: 0.1496 - lr: 0.0100\n","Epoch 29/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5405 - accuracy: 0.6942 - dice_coefficient: 0.2414 - jaccard_index: 0.1380 - sensitivity: 0.7579 - specificity: 0.6896 - precision: 0.1453\n","Epoch 29: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 710s 7s/step - loss: 0.5405 - accuracy: 0.6942 - dice_coefficient: 0.2414 - jaccard_index: 0.1380 - sensitivity: 0.7579 - specificity: 0.6896 - precision: 0.1453 - val_loss: 0.5218 - val_accuracy: 0.6862 - val_dice_coefficient: 0.2400 - val_jaccard_index: 0.1367 - val_sensitivity: 0.8073 - val_specificity: 0.6782 - val_precision: 0.1416 - lr: 0.0100\n","Epoch 30/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.6912 - dice_coefficient: 0.2406 - jaccard_index: 0.1375 - sensitivity: 0.7666 - specificity: 0.6852 - precision: 0.1442\n","Epoch 30: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 707s 7s/step - loss: 0.5381 - accuracy: 0.6912 - dice_coefficient: 0.2406 - jaccard_index: 0.1375 - sensitivity: 0.7666 - specificity: 0.6852 - precision: 0.1442 - val_loss: 0.5265 - val_accuracy: 0.6346 - val_dice_coefficient: 0.2228 - val_jaccard_index: 0.1257 - val_sensitivity: 0.8527 - val_specificity: 0.6201 - val_precision: 0.1286 - lr: 0.0100\n","Epoch 31/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.6863 - dice_coefficient: 0.2393 - jaccard_index: 0.1366 - sensitivity: 0.7701 - specificity: 0.6799 - precision: 0.1433\n","Epoch 31: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 729s 7s/step - loss: 0.5395 - accuracy: 0.6863 - dice_coefficient: 0.2393 - jaccard_index: 0.1366 - sensitivity: 0.7701 - specificity: 0.6799 - precision: 0.1433 - val_loss: 0.5191 - val_accuracy: 0.7023 - val_dice_coefficient: 0.2442 - val_jaccard_index: 0.1395 - val_sensitivity: 0.7793 - val_specificity: 0.6971 - val_precision: 0.1457 - lr: 0.0100\n","Epoch 32/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.6983 - dice_coefficient: 0.2448 - jaccard_index: 0.1401 - sensitivity: 0.7681 - specificity: 0.6918 - precision: 0.1469\n","Epoch 32: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 720s 7s/step - loss: 0.5310 - accuracy: 0.6983 - dice_coefficient: 0.2448 - jaccard_index: 0.1401 - sensitivity: 0.7681 - specificity: 0.6918 - precision: 0.1469 - val_loss: 0.5079 - val_accuracy: 0.6894 - val_dice_coefficient: 0.2454 - val_jaccard_index: 0.1403 - val_sensitivity: 0.8205 - val_specificity: 0.6806 - val_precision: 0.1449 - lr: 0.0100\n","Epoch 33/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.6974 - dice_coefficient: 0.2459 - jaccard_index: 0.1407 - sensitivity: 0.7721 - specificity: 0.6916 - precision: 0.1473\n","Epoch 33: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 723s 7s/step - loss: 0.5297 - accuracy: 0.6974 - dice_coefficient: 0.2459 - jaccard_index: 0.1407 - sensitivity: 0.7721 - specificity: 0.6916 - precision: 0.1473 - val_loss: 0.5088 - val_accuracy: 0.7311 - val_dice_coefficient: 0.2583 - val_jaccard_index: 0.1487 - val_sensitivity: 0.7620 - val_specificity: 0.7290 - val_precision: 0.1564 - lr: 0.0100\n","Epoch 34/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.6998 - dice_coefficient: 0.2498 - jaccard_index: 0.1435 - sensitivity: 0.7822 - specificity: 0.6931 - precision: 0.1501\n","Epoch 34: val_dice_coefficient did not improve from 0.26125\n","108/108 [==============================] - 750s 7s/step - loss: 0.5234 - accuracy: 0.6998 - dice_coefficient: 0.2498 - jaccard_index: 0.1435 - sensitivity: 0.7822 - specificity: 0.6931 - precision: 0.1501 - val_loss: 0.4994 - val_accuracy: 0.6864 - val_dice_coefficient: 0.2455 - val_jaccard_index: 0.1403 - val_sensitivity: 0.8319 - val_specificity: 0.6767 - val_precision: 0.1445 - lr: 0.0100\n","Epoch 35/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5237 - accuracy: 0.7023 - dice_coefficient: 0.2508 - jaccard_index: 0.1439 - sensitivity: 0.7780 - specificity: 0.6967 - precision: 0.1507\n","Epoch 35: val_dice_coefficient improved from 0.26125 to 0.27115, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 760s 7s/step - loss: 0.5237 - accuracy: 0.7023 - dice_coefficient: 0.2508 - jaccard_index: 0.1439 - sensitivity: 0.7780 - specificity: 0.6967 - precision: 0.1507 - val_loss: 0.4921 - val_accuracy: 0.7425 - val_dice_coefficient: 0.2712 - val_jaccard_index: 0.1572 - val_sensitivity: 0.7810 - val_specificity: 0.7399 - val_precision: 0.1647 - lr: 0.0100\n","Epoch 36/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7032 - dice_coefficient: 0.2527 - jaccard_index: 0.1454 - sensitivity: 0.7850 - specificity: 0.6966 - precision: 0.1520\n","Epoch 36: val_dice_coefficient did not improve from 0.27115\n","108/108 [==============================] - 748s 7s/step - loss: 0.5177 - accuracy: 0.7032 - dice_coefficient: 0.2527 - jaccard_index: 0.1454 - sensitivity: 0.7850 - specificity: 0.6966 - precision: 0.1520 - val_loss: 0.5109 - val_accuracy: 0.6543 - val_dice_coefficient: 0.2323 - val_jaccard_index: 0.1320 - val_sensitivity: 0.8452 - val_specificity: 0.6417 - val_precision: 0.1353 - lr: 0.0100\n","Epoch 37/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.7009 - dice_coefficient: 0.2524 - jaccard_index: 0.1451 - sensitivity: 0.7869 - specificity: 0.6933 - precision: 0.1517\n","Epoch 37: val_dice_coefficient improved from 0.27115 to 0.27972, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 741s 7s/step - loss: 0.5182 - accuracy: 0.7009 - dice_coefficient: 0.2524 - jaccard_index: 0.1451 - sensitivity: 0.7869 - specificity: 0.6933 - precision: 0.1517 - val_loss: 0.5000 - val_accuracy: 0.7653 - val_dice_coefficient: 0.2797 - val_jaccard_index: 0.1630 - val_sensitivity: 0.7420 - val_specificity: 0.7667 - val_precision: 0.1731 - lr: 0.0100\n","Epoch 38/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.7058 - dice_coefficient: 0.2548 - jaccard_index: 0.1466 - sensitivity: 0.7881 - specificity: 0.6991 - precision: 0.1533\n","Epoch 38: val_dice_coefficient did not improve from 0.27972\n","108/108 [==============================] - 737s 7s/step - loss: 0.5153 - accuracy: 0.7058 - dice_coefficient: 0.2548 - jaccard_index: 0.1466 - sensitivity: 0.7881 - specificity: 0.6991 - precision: 0.1533 - val_loss: 0.4849 - val_accuracy: 0.7119 - val_dice_coefficient: 0.2612 - val_jaccard_index: 0.1505 - val_sensitivity: 0.8302 - val_specificity: 0.7038 - val_precision: 0.1554 - lr: 0.0100\n","Epoch 39/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5121 - accuracy: 0.7078 - dice_coefficient: 0.2580 - jaccard_index: 0.1487 - sensitivity: 0.7898 - specificity: 0.7014 - precision: 0.1554\n","Epoch 39: val_dice_coefficient did not improve from 0.27972\n","108/108 [==============================] - 731s 7s/step - loss: 0.5121 - accuracy: 0.7078 - dice_coefficient: 0.2580 - jaccard_index: 0.1487 - sensitivity: 0.7898 - specificity: 0.7014 - precision: 0.1554 - val_loss: 0.4961 - val_accuracy: 0.7625 - val_dice_coefficient: 0.2772 - val_jaccard_index: 0.1613 - val_sensitivity: 0.7434 - val_specificity: 0.7634 - val_precision: 0.1710 - lr: 0.0100\n","Epoch 40/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.7058 - dice_coefficient: 0.2574 - jaccard_index: 0.1483 - sensitivity: 0.7939 - specificity: 0.6994 - precision: 0.1548\n","Epoch 40: val_dice_coefficient did not improve from 0.27972\n","108/108 [==============================] - 736s 7s/step - loss: 0.5119 - accuracy: 0.7058 - dice_coefficient: 0.2574 - jaccard_index: 0.1483 - sensitivity: 0.7939 - specificity: 0.6994 - precision: 0.1548 - val_loss: 0.4933 - val_accuracy: 0.7448 - val_dice_coefficient: 0.2708 - val_jaccard_index: 0.1570 - val_sensitivity: 0.7728 - val_specificity: 0.7428 - val_precision: 0.1648 - lr: 0.0100\n","Epoch 41/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.7122 - dice_coefficient: 0.2601 - jaccard_index: 0.1500 - sensitivity: 0.7927 - specificity: 0.7055 - precision: 0.1565\n","Epoch 41: val_dice_coefficient did not improve from 0.27972\n","108/108 [==============================] - 735s 7s/step - loss: 0.5078 - accuracy: 0.7122 - dice_coefficient: 0.2601 - jaccard_index: 0.1500 - sensitivity: 0.7927 - specificity: 0.7055 - precision: 0.1565 - val_loss: 0.4855 - val_accuracy: 0.6913 - val_dice_coefficient: 0.2530 - val_jaccard_index: 0.1452 - val_sensitivity: 0.8514 - val_specificity: 0.6803 - val_precision: 0.1489 - lr: 0.0100\n","Epoch 42/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.7118 - dice_coefficient: 0.2616 - jaccard_index: 0.1511 - sensitivity: 0.8007 - specificity: 0.7047 - precision: 0.1573\n","Epoch 42: val_dice_coefficient did not improve from 0.27972\n","108/108 [==============================] - 727s 7s/step - loss: 0.5036 - accuracy: 0.7118 - dice_coefficient: 0.2616 - jaccard_index: 0.1511 - sensitivity: 0.8007 - specificity: 0.7047 - precision: 0.1573 - val_loss: 0.5026 - val_accuracy: 0.7608 - val_dice_coefficient: 0.2749 - val_jaccard_index: 0.1597 - val_sensitivity: 0.7381 - val_specificity: 0.7620 - val_precision: 0.1695 - lr: 0.0100\n","Epoch 43/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5052 - accuracy: 0.7111 - dice_coefficient: 0.2610 - jaccard_index: 0.1508 - sensitivity: 0.7966 - specificity: 0.7039 - precision: 0.1575\n","Epoch 43: val_dice_coefficient improved from 0.27972 to 0.28354, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 742s 7s/step - loss: 0.5052 - accuracy: 0.7111 - dice_coefficient: 0.2610 - jaccard_index: 0.1508 - sensitivity: 0.7966 - specificity: 0.7039 - precision: 0.1575 - val_loss: 0.4760 - val_accuracy: 0.7541 - val_dice_coefficient: 0.2835 - val_jaccard_index: 0.1655 - val_sensitivity: 0.7928 - val_specificity: 0.7511 - val_precision: 0.1730 - lr: 0.0100\n","Epoch 44/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5028 - accuracy: 0.7127 - dice_coefficient: 0.2626 - jaccard_index: 0.1518 - sensitivity: 0.7975 - specificity: 0.7053 - precision: 0.1584\n","Epoch 44: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 733s 7s/step - loss: 0.5028 - accuracy: 0.7127 - dice_coefficient: 0.2626 - jaccard_index: 0.1518 - sensitivity: 0.7975 - specificity: 0.7053 - precision: 0.1584 - val_loss: 0.4788 - val_accuracy: 0.7194 - val_dice_coefficient: 0.2668 - val_jaccard_index: 0.1543 - val_sensitivity: 0.8313 - val_specificity: 0.7116 - val_precision: 0.1593 - lr: 0.0100\n","Epoch 45/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7190 - dice_coefficient: 0.2685 - jaccard_index: 0.1555 - sensitivity: 0.8063 - specificity: 0.7121 - precision: 0.1618\n","Epoch 45: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 734s 7s/step - loss: 0.4953 - accuracy: 0.7190 - dice_coefficient: 0.2685 - jaccard_index: 0.1555 - sensitivity: 0.8063 - specificity: 0.7121 - precision: 0.1618 - val_loss: 0.4861 - val_accuracy: 0.7104 - val_dice_coefficient: 0.2593 - val_jaccard_index: 0.1493 - val_sensitivity: 0.8237 - val_specificity: 0.7024 - val_precision: 0.1544 - lr: 0.0100\n","Epoch 46/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7108 - dice_coefficient: 0.2623 - jaccard_index: 0.1516 - sensitivity: 0.7972 - specificity: 0.7032 - precision: 0.1585\n","Epoch 46: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 733s 7s/step - loss: 0.5040 - accuracy: 0.7108 - dice_coefficient: 0.2623 - jaccard_index: 0.1516 - sensitivity: 0.7972 - specificity: 0.7032 - precision: 0.1585 - val_loss: 0.4800 - val_accuracy: 0.7179 - val_dice_coefficient: 0.2647 - val_jaccard_index: 0.1529 - val_sensitivity: 0.8258 - val_specificity: 0.7103 - val_precision: 0.1580 - lr: 0.0100\n","Epoch 47/150\n","108/108 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7131 - dice_coefficient: 0.2642 - jaccard_index: 0.1529 - sensitivity: 0.8029 - specificity: 0.7061 - precision: 0.1592\n","Epoch 47: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 733s 7s/step - loss: 0.5005 - accuracy: 0.7131 - dice_coefficient: 0.2642 - jaccard_index: 0.1529 - sensitivity: 0.8029 - specificity: 0.7061 - precision: 0.1592 - val_loss: 0.4803 - val_accuracy: 0.7250 - val_dice_coefficient: 0.2674 - val_jaccard_index: 0.1547 - val_sensitivity: 0.8168 - val_specificity: 0.7184 - val_precision: 0.1602 - lr: 0.0100\n","Epoch 48/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.7135 - dice_coefficient: 0.2640 - jaccard_index: 0.1527 - sensitivity: 0.8034 - specificity: 0.7060 - precision: 0.1591\n","Epoch 48: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 736s 7s/step - loss: 0.4977 - accuracy: 0.7135 - dice_coefficient: 0.2640 - jaccard_index: 0.1527 - sensitivity: 0.8034 - specificity: 0.7060 - precision: 0.1591 - val_loss: 0.4703 - val_accuracy: 0.7457 - val_dice_coefficient: 0.2813 - val_jaccard_index: 0.1640 - val_sensitivity: 0.8110 - val_specificity: 0.7409 - val_precision: 0.1705 - lr: 0.0100\n","Epoch 49/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.7197 - dice_coefficient: 0.2688 - jaccard_index: 0.1559 - sensitivity: 0.8035 - specificity: 0.7125 - precision: 0.1626\n","Epoch 49: val_dice_coefficient did not improve from 0.28354\n","108/108 [==============================] - 739s 7s/step - loss: 0.4945 - accuracy: 0.7197 - dice_coefficient: 0.2688 - jaccard_index: 0.1559 - sensitivity: 0.8035 - specificity: 0.7125 - precision: 0.1626 - val_loss: 0.4752 - val_accuracy: 0.7010 - val_dice_coefficient: 0.2594 - val_jaccard_index: 0.1494 - val_sensitivity: 0.8539 - val_specificity: 0.6905 - val_precision: 0.1533 - lr: 0.0100\n","Epoch 50/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4905 - accuracy: 0.7200 - dice_coefficient: 0.2694 - jaccard_index: 0.1562 - sensitivity: 0.8075 - specificity: 0.7126 - precision: 0.1625\n","Epoch 50: val_dice_coefficient improved from 0.28354 to 0.28659, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 745s 7s/step - loss: 0.4905 - accuracy: 0.7200 - dice_coefficient: 0.2694 - jaccard_index: 0.1562 - sensitivity: 0.8075 - specificity: 0.7126 - precision: 0.1625 - val_loss: 0.4783 - val_accuracy: 0.7627 - val_dice_coefficient: 0.2866 - val_jaccard_index: 0.1675 - val_sensitivity: 0.7784 - val_specificity: 0.7613 - val_precision: 0.1760 - lr: 0.0100\n","Epoch 51/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.7241 - dice_coefficient: 0.2732 - jaccard_index: 0.1588 - sensitivity: 0.8127 - specificity: 0.7165 - precision: 0.1650\n","Epoch 51: val_dice_coefficient did not improve from 0.28659\n","108/108 [==============================] - 733s 7s/step - loss: 0.4869 - accuracy: 0.7241 - dice_coefficient: 0.2732 - jaccard_index: 0.1588 - sensitivity: 0.8127 - specificity: 0.7165 - precision: 0.1650 - val_loss: 0.4732 - val_accuracy: 0.7018 - val_dice_coefficient: 0.2606 - val_jaccard_index: 0.1501 - val_sensitivity: 0.8557 - val_specificity: 0.6910 - val_precision: 0.1540 - lr: 0.0099\n","Epoch 52/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.7181 - dice_coefficient: 0.2701 - jaccard_index: 0.1569 - sensitivity: 0.8153 - specificity: 0.7106 - precision: 0.1631\n","Epoch 52: val_dice_coefficient improved from 0.28659 to 0.28724, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 747s 7s/step - loss: 0.4898 - accuracy: 0.7181 - dice_coefficient: 0.2701 - jaccard_index: 0.1569 - sensitivity: 0.8153 - specificity: 0.7106 - precision: 0.1631 - val_loss: 0.4745 - val_accuracy: 0.7614 - val_dice_coefficient: 0.2872 - val_jaccard_index: 0.1679 - val_sensitivity: 0.7836 - val_specificity: 0.7593 - val_precision: 0.1762 - lr: 0.0098\n","Epoch 53/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.7221 - dice_coefficient: 0.2739 - jaccard_index: 0.1592 - sensitivity: 0.8167 - specificity: 0.7148 - precision: 0.1654\n","Epoch 53: val_dice_coefficient improved from 0.28724 to 0.30379, saving model to /gdrive/My Drive/Dataset/Models/best_mevit_model_10\n","108/108 [==============================] - 749s 7s/step - loss: 0.4851 - accuracy: 0.7221 - dice_coefficient: 0.2739 - jaccard_index: 0.1592 - sensitivity: 0.8167 - specificity: 0.7148 - precision: 0.1654 - val_loss: 0.4851 - val_accuracy: 0.7926 - val_dice_coefficient: 0.3038 - val_jaccard_index: 0.1794 - val_sensitivity: 0.7369 - val_specificity: 0.7957 - val_precision: 0.1916 - lr: 0.0097\n","Epoch 54/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4823 - accuracy: 0.7251 - dice_coefficient: 0.2743 - jaccard_index: 0.1594 - sensitivity: 0.8183 - specificity: 0.7178 - precision: 0.1654\n","Epoch 54: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 737s 7s/step - loss: 0.4823 - accuracy: 0.7251 - dice_coefficient: 0.2743 - jaccard_index: 0.1594 - sensitivity: 0.8183 - specificity: 0.7178 - precision: 0.1654 - val_loss: 0.4754 - val_accuracy: 0.7456 - val_dice_coefficient: 0.2805 - val_jaccard_index: 0.1634 - val_sensitivity: 0.8053 - val_specificity: 0.7410 - val_precision: 0.1702 - lr: 0.0096\n","Epoch 55/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.7258 - dice_coefficient: 0.2742 - jaccard_index: 0.1594 - sensitivity: 0.8137 - specificity: 0.7185 - precision: 0.1658\n","Epoch 55: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 745s 7s/step - loss: 0.4837 - accuracy: 0.7258 - dice_coefficient: 0.2742 - jaccard_index: 0.1594 - sensitivity: 0.8137 - specificity: 0.7185 - precision: 0.1658 - val_loss: 0.4728 - val_accuracy: 0.6892 - val_dice_coefficient: 0.2550 - val_jaccard_index: 0.1464 - val_sensitivity: 0.8669 - val_specificity: 0.6769 - val_precision: 0.1497 - lr: 0.0095\n","Epoch 56/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4801 - accuracy: 0.7271 - dice_coefficient: 0.2765 - jaccard_index: 0.1610 - sensitivity: 0.8166 - specificity: 0.7200 - precision: 0.1673\n","Epoch 56: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 738s 7s/step - loss: 0.4801 - accuracy: 0.7271 - dice_coefficient: 0.2765 - jaccard_index: 0.1610 - sensitivity: 0.8166 - specificity: 0.7200 - precision: 0.1673 - val_loss: 0.4673 - val_accuracy: 0.7606 - val_dice_coefficient: 0.2895 - val_jaccard_index: 0.1695 - val_sensitivity: 0.7943 - val_specificity: 0.7578 - val_precision: 0.1773 - lr: 0.0094\n","Epoch 57/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.7258 - dice_coefficient: 0.2753 - jaccard_index: 0.1602 - sensitivity: 0.8180 - specificity: 0.7179 - precision: 0.1662\n","Epoch 57: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 730s 7s/step - loss: 0.4806 - accuracy: 0.7258 - dice_coefficient: 0.2753 - jaccard_index: 0.1602 - sensitivity: 0.8180 - specificity: 0.7179 - precision: 0.1662 - val_loss: 0.4666 - val_accuracy: 0.7082 - val_dice_coefficient: 0.2644 - val_jaccard_index: 0.1526 - val_sensitivity: 0.8541 - val_specificity: 0.6979 - val_precision: 0.1566 - lr: 0.0093\n","Epoch 58/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.7230 - dice_coefficient: 0.2737 - jaccard_index: 0.1590 - sensitivity: 0.8178 - specificity: 0.7158 - precision: 0.1652\n","Epoch 58: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 739s 7s/step - loss: 0.4843 - accuracy: 0.7230 - dice_coefficient: 0.2737 - jaccard_index: 0.1590 - sensitivity: 0.8178 - specificity: 0.7158 - precision: 0.1652 - val_loss: 0.4686 - val_accuracy: 0.7629 - val_dice_coefficient: 0.2909 - val_jaccard_index: 0.1704 - val_sensitivity: 0.7919 - val_specificity: 0.7604 - val_precision: 0.1784 - lr: 0.0092\n","Epoch 59/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.7283 - dice_coefficient: 0.2776 - jaccard_index: 0.1616 - sensitivity: 0.8164 - specificity: 0.7208 - precision: 0.1679\n","Epoch 59: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 736s 7s/step - loss: 0.4784 - accuracy: 0.7283 - dice_coefficient: 0.2776 - jaccard_index: 0.1616 - sensitivity: 0.8164 - specificity: 0.7208 - precision: 0.1679 - val_loss: 0.4657 - val_accuracy: 0.7232 - val_dice_coefficient: 0.2709 - val_jaccard_index: 0.1569 - val_sensitivity: 0.8395 - val_specificity: 0.7149 - val_precision: 0.1618 - lr: 0.0091\n","Epoch 60/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4775 - accuracy: 0.7255 - dice_coefficient: 0.2753 - jaccard_index: 0.1601 - sensitivity: 0.8201 - specificity: 0.7171 - precision: 0.1662\n","Epoch 60: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 738s 7s/step - loss: 0.4775 - accuracy: 0.7255 - dice_coefficient: 0.2753 - jaccard_index: 0.1601 - sensitivity: 0.8201 - specificity: 0.7171 - precision: 0.1662 - val_loss: 0.4635 - val_accuracy: 0.7219 - val_dice_coefficient: 0.2713 - val_jaccard_index: 0.1571 - val_sensitivity: 0.8439 - val_specificity: 0.7132 - val_precision: 0.1618 - lr: 0.0090\n","Epoch 61/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4792 - accuracy: 0.7255 - dice_coefficient: 0.2737 - jaccard_index: 0.1592 - sensitivity: 0.8152 - specificity: 0.7177 - precision: 0.1652\n","Epoch 61: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 738s 7s/step - loss: 0.4792 - accuracy: 0.7255 - dice_coefficient: 0.2737 - jaccard_index: 0.1592 - sensitivity: 0.8152 - specificity: 0.7177 - precision: 0.1652 - val_loss: 0.4697 - val_accuracy: 0.7482 - val_dice_coefficient: 0.2840 - val_jaccard_index: 0.1658 - val_sensitivity: 0.8109 - val_specificity: 0.7434 - val_precision: 0.1725 - lr: 0.0090\n","Epoch 62/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.7290 - dice_coefficient: 0.2788 - jaccard_index: 0.1625 - sensitivity: 0.8212 - specificity: 0.7223 - precision: 0.1685\n","Epoch 62: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 734s 7s/step - loss: 0.4771 - accuracy: 0.7290 - dice_coefficient: 0.2788 - jaccard_index: 0.1625 - sensitivity: 0.8212 - specificity: 0.7223 - precision: 0.1685 - val_loss: 0.4666 - val_accuracy: 0.7095 - val_dice_coefficient: 0.2651 - val_jaccard_index: 0.1531 - val_sensitivity: 0.8530 - val_specificity: 0.6994 - val_precision: 0.1572 - lr: 0.0089\n","Epoch 63/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.7290 - dice_coefficient: 0.2787 - jaccard_index: 0.1624 - sensitivity: 0.8198 - specificity: 0.7214 - precision: 0.1686\n","Epoch 63: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 754s 7s/step - loss: 0.4743 - accuracy: 0.7290 - dice_coefficient: 0.2787 - jaccard_index: 0.1624 - sensitivity: 0.8198 - specificity: 0.7214 - precision: 0.1686 - val_loss: 0.4634 - val_accuracy: 0.7145 - val_dice_coefficient: 0.2684 - val_jaccard_index: 0.1552 - val_sensitivity: 0.8526 - val_specificity: 0.7046 - val_precision: 0.1594 - lr: 0.0088\n","Epoch 64/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.7293 - dice_coefficient: 0.2790 - jaccard_index: 0.1627 - sensitivity: 0.8221 - specificity: 0.7216 - precision: 0.1687\n","Epoch 64: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 744s 7s/step - loss: 0.4724 - accuracy: 0.7293 - dice_coefficient: 0.2790 - jaccard_index: 0.1627 - sensitivity: 0.8221 - specificity: 0.7216 - precision: 0.1687 - val_loss: 0.4672 - val_accuracy: 0.7670 - val_dice_coefficient: 0.2936 - val_jaccard_index: 0.1723 - val_sensitivity: 0.7896 - val_specificity: 0.7649 - val_precision: 0.1805 - lr: 0.0087\n","Epoch 65/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4734 - accuracy: 0.7294 - dice_coefficient: 0.2798 - jaccard_index: 0.1632 - sensitivity: 0.8220 - specificity: 0.7212 - precision: 0.1694\n","Epoch 65: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 754s 7s/step - loss: 0.4734 - accuracy: 0.7294 - dice_coefficient: 0.2798 - jaccard_index: 0.1632 - sensitivity: 0.8220 - specificity: 0.7212 - precision: 0.1694 - val_loss: 0.4688 - val_accuracy: 0.7694 - val_dice_coefficient: 0.2953 - val_jaccard_index: 0.1734 - val_sensitivity: 0.7857 - val_specificity: 0.7676 - val_precision: 0.1820 - lr: 0.0086\n","Epoch 66/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.7290 - dice_coefficient: 0.2794 - jaccard_index: 0.1630 - sensitivity: 0.8212 - specificity: 0.7213 - precision: 0.1691\n","Epoch 66: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 724s 7s/step - loss: 0.4732 - accuracy: 0.7290 - dice_coefficient: 0.2794 - jaccard_index: 0.1630 - sensitivity: 0.8212 - specificity: 0.7213 - precision: 0.1691 - val_loss: 0.4604 - val_accuracy: 0.7417 - val_dice_coefficient: 0.2818 - val_jaccard_index: 0.1642 - val_sensitivity: 0.8252 - val_specificity: 0.7354 - val_precision: 0.1701 - lr: 0.0085\n","Epoch 67/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.7293 - dice_coefficient: 0.2805 - jaccard_index: 0.1636 - sensitivity: 0.8279 - specificity: 0.7216 - precision: 0.1694\n","Epoch 67: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 729s 7s/step - loss: 0.4708 - accuracy: 0.7293 - dice_coefficient: 0.2805 - jaccard_index: 0.1636 - sensitivity: 0.8279 - specificity: 0.7216 - precision: 0.1694 - val_loss: 0.4636 - val_accuracy: 0.7176 - val_dice_coefficient: 0.2690 - val_jaccard_index: 0.1556 - val_sensitivity: 0.8463 - val_specificity: 0.7084 - val_precision: 0.1601 - lr: 0.0084\n","Epoch 68/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4691 - accuracy: 0.7318 - dice_coefficient: 0.2820 - jaccard_index: 0.1647 - sensitivity: 0.8265 - specificity: 0.7243 - precision: 0.1707\n","Epoch 68: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 734s 7s/step - loss: 0.4691 - accuracy: 0.7318 - dice_coefficient: 0.2820 - jaccard_index: 0.1647 - sensitivity: 0.8265 - specificity: 0.7243 - precision: 0.1707 - val_loss: 0.4618 - val_accuracy: 0.6977 - val_dice_coefficient: 0.2610 - val_jaccard_index: 0.1503 - val_sensitivity: 0.8707 - val_specificity: 0.6855 - val_precision: 0.1537 - lr: 0.0083\n","Epoch 69/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.7276 - dice_coefficient: 0.2783 - jaccard_index: 0.1622 - sensitivity: 0.8275 - specificity: 0.7195 - precision: 0.1680\n","Epoch 69: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 740s 7s/step - loss: 0.4721 - accuracy: 0.7276 - dice_coefficient: 0.2783 - jaccard_index: 0.1622 - sensitivity: 0.8275 - specificity: 0.7195 - precision: 0.1680 - val_loss: 0.4592 - val_accuracy: 0.7457 - val_dice_coefficient: 0.2856 - val_jaccard_index: 0.1668 - val_sensitivity: 0.8246 - val_specificity: 0.7398 - val_precision: 0.1730 - lr: 0.0083\n","Epoch 70/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7331 - dice_coefficient: 0.2813 - jaccard_index: 0.1641 - sensitivity: 0.8209 - specificity: 0.7252 - precision: 0.1704\n","Epoch 70: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 745s 7s/step - loss: 0.4699 - accuracy: 0.7331 - dice_coefficient: 0.2813 - jaccard_index: 0.1641 - sensitivity: 0.8209 - specificity: 0.7252 - precision: 0.1704 - val_loss: 0.4698 - val_accuracy: 0.6788 - val_dice_coefficient: 0.2523 - val_jaccard_index: 0.1446 - val_sensitivity: 0.8831 - val_specificity: 0.6645 - val_precision: 0.1474 - lr: 0.0082\n","Epoch 71/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.7301 - dice_coefficient: 0.2819 - jaccard_index: 0.1645 - sensitivity: 0.8294 - specificity: 0.7216 - precision: 0.1704\n","Epoch 71: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 751s 7s/step - loss: 0.4689 - accuracy: 0.7301 - dice_coefficient: 0.2819 - jaccard_index: 0.1645 - sensitivity: 0.8294 - specificity: 0.7216 - precision: 0.1704 - val_loss: 0.4635 - val_accuracy: 0.7599 - val_dice_coefficient: 0.2917 - val_jaccard_index: 0.1710 - val_sensitivity: 0.8029 - val_specificity: 0.7563 - val_precision: 0.1785 - lr: 0.0081\n","Epoch 72/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.7337 - dice_coefficient: 0.2827 - jaccard_index: 0.1650 - sensitivity: 0.8243 - specificity: 0.7260 - precision: 0.1712\n","Epoch 72: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 774s 7s/step - loss: 0.4672 - accuracy: 0.7337 - dice_coefficient: 0.2827 - jaccard_index: 0.1650 - sensitivity: 0.8243 - specificity: 0.7260 - precision: 0.1712 - val_loss: 0.4638 - val_accuracy: 0.6949 - val_dice_coefficient: 0.2594 - val_jaccard_index: 0.1493 - val_sensitivity: 0.8706 - val_specificity: 0.6826 - val_precision: 0.1526 - lr: 0.0080\n","Epoch 73/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.7313 - dice_coefficient: 0.2832 - jaccard_index: 0.1654 - sensitivity: 0.8315 - specificity: 0.7234 - precision: 0.1713\n","Epoch 73: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 751s 7s/step - loss: 0.4666 - accuracy: 0.7313 - dice_coefficient: 0.2832 - jaccard_index: 0.1654 - sensitivity: 0.8315 - specificity: 0.7234 - precision: 0.1713 - val_loss: 0.4613 - val_accuracy: 0.7544 - val_dice_coefficient: 0.2889 - val_jaccard_index: 0.1691 - val_sensitivity: 0.8118 - val_specificity: 0.7499 - val_precision: 0.1759 - lr: 0.0079\n","Epoch 74/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.7339 - dice_coefficient: 0.2840 - jaccard_index: 0.1660 - sensitivity: 0.8279 - specificity: 0.7258 - precision: 0.1720\n","Epoch 74: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 798s 7s/step - loss: 0.4653 - accuracy: 0.7339 - dice_coefficient: 0.2840 - jaccard_index: 0.1660 - sensitivity: 0.8279 - specificity: 0.7258 - precision: 0.1720 - val_loss: 0.4590 - val_accuracy: 0.7438 - val_dice_coefficient: 0.2832 - val_jaccard_index: 0.1651 - val_sensitivity: 0.8235 - val_specificity: 0.7378 - val_precision: 0.1711 - lr: 0.0079\n","Epoch 75/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.7333 - dice_coefficient: 0.2825 - jaccard_index: 0.1649 - sensitivity: 0.8265 - specificity: 0.7258 - precision: 0.1709\n","Epoch 75: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 747s 7s/step - loss: 0.4658 - accuracy: 0.7333 - dice_coefficient: 0.2825 - jaccard_index: 0.1649 - sensitivity: 0.8265 - specificity: 0.7258 - precision: 0.1709 - val_loss: 0.4594 - val_accuracy: 0.7472 - val_dice_coefficient: 0.2854 - val_jaccard_index: 0.1666 - val_sensitivity: 0.8218 - val_specificity: 0.7415 - val_precision: 0.1728 - lr: 0.0078\n","Epoch 76/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.7340 - dice_coefficient: 0.2841 - jaccard_index: 0.1660 - sensitivity: 0.8299 - specificity: 0.7259 - precision: 0.1718\n","Epoch 76: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 711s 7s/step - loss: 0.4635 - accuracy: 0.7340 - dice_coefficient: 0.2841 - jaccard_index: 0.1660 - sensitivity: 0.8299 - specificity: 0.7259 - precision: 0.1718 - val_loss: 0.4572 - val_accuracy: 0.7454 - val_dice_coefficient: 0.2848 - val_jaccard_index: 0.1662 - val_sensitivity: 0.8251 - val_specificity: 0.7394 - val_precision: 0.1723 - lr: 0.0077\n","Epoch 77/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.7329 - dice_coefficient: 0.2824 - jaccard_index: 0.1648 - sensitivity: 0.8279 - specificity: 0.7246 - precision: 0.1707\n","Epoch 77: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 829s 8s/step - loss: 0.4651 - accuracy: 0.7329 - dice_coefficient: 0.2824 - jaccard_index: 0.1648 - sensitivity: 0.8279 - specificity: 0.7246 - precision: 0.1707 - val_loss: 0.4566 - val_accuracy: 0.7239 - val_dice_coefficient: 0.2740 - val_jaccard_index: 0.1589 - val_sensitivity: 0.8485 - val_specificity: 0.7149 - val_precision: 0.1636 - lr: 0.0076\n","Epoch 78/150\n","108/108 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.7331 - dice_coefficient: 0.2838 - jaccard_index: 0.1659 - sensitivity: 0.8317 - specificity: 0.7250 - precision: 0.1717\n","Epoch 78: val_dice_coefficient did not improve from 0.30379\n","108/108 [==============================] - 887s 8s/step - loss: 0.4632 - accuracy: 0.7331 - dice_coefficient: 0.2838 - jaccard_index: 0.1659 - sensitivity: 0.8317 - specificity: 0.7250 - precision: 0.1717 - val_loss: 0.4587 - val_accuracy: 0.7186 - val_dice_coefficient: 0.2705 - val_jaccard_index: 0.1566 - val_sensitivity: 0.8498 - val_specificity: 0.7092 - val_precision: 0.1611 - lr: 0.0075\n","Epoch 79/150\n"," 27/108 [======\u003e.......................] - ETA: 10:25 - loss: 0.4689 - accuracy: 0.7318 - dice_coefficient: 0.2892 - jaccard_index: 0.1692 - sensitivity: 0.8326 - specificity: 0.7234 - precision: 0.1753"]}],"source":["# Setup callbacks\n","early_stopping = EarlyStopping(\n","    monitor='val_dice_coefficient',\n","    patience=30,  # Reduced patience\n","    verbose=1,\n","    mode='max',\n","    restore_best_weights=True\n",")\n","\n","model_checkpoint = ModelCheckpoint(\n","    f'/gdrive/My Drive/Dataset/Models/best_{model_name}',  # Path where the model will be saved\n","    monitor='val_dice_coefficient',  # Save the model based on the maximum dice_coefficient value\n","    verbose=1,\n","    save_best_only=True,\n","    mode='max'\n",")\n","\n","# Fit the model\n","history = model.fit(\n","    X_train, y_train,\n","    batch_size=16,  # Experiment with different values\n","    epochs=150,\n","    verbose=1,\n","    validation_data=(X_val, y_val),\n","    callbacks=[model_checkpoint, early_stopping, lr_scheduler]\n",")\n","\n","# Save the model\n","model.save(f'/gdrive/My Drive/Dataset/Models/{model_name}.h5')"]},{"cell_type":"markdown","metadata":{"id":"XpKxuoOXtGOe"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"eEY45m0AsTyF"},"source":["Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A3QbrIXpsU9K"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","from sklearn.metrics import roc_auc_score\n","\n","from sklearn.metrics import roc_auc_score\n","\n","# Evaluation functions\n","def plot_training_history(history):\n","    plt.figure(figsize=(12, 6))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Loss Over Epochs')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['dice_coefficient'], label='Training Dice Coefficient')\n","    plt.plot(history.history['val_dice_coefficient'], label='Validation Dice Coefficient')\n","    plt.title('Dice Coefficient Over Epochs')\n","    plt.legend()\n","\n","    plt.show()\n","\n","def show_predictions(X, y_true, y_pred, threshold=threshold, num_samples=5):\n","    indices = np.random.choice(range(len(X)), num_samples, replace=False)\n","\n","    for i in indices:\n","        plt.figure(figsize=(12, 6))\n","        plt.subplot(1, 3, 1)\n","        plt.imshow(X[i])\n","        plt.title(f'Original Image [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 2)\n","        plt.imshow(y_true[i].squeeze(), cmap='gray')\n","        plt.title(f'True Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.subplot(1, 3, 3)\n","        plt.imshow(y_pred[i].squeeze() \u003e threshold, cmap='gray')  # Apply a threshold to convert probabilities to binary mask\n","        plt.title(f'Predicted Mask [{i}]')\n","        plt.axis('off')\n","\n","        plt.show()\n","\n","def plot_confusion_matrix(y_true, y_pred, threshold=threshold):\n","    y_true_f = y_true.flatten()\n","    y_pred_f = (y_pred.flatten() \u003e threshold).astype(int)  # Thresholding probabilities\n","\n","    cm = confusion_matrix(y_true_f, y_pred_f)\n","    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the confusion matrix\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","\n","    labels = ['True Negative (Correct: No Buildings)', 'False Positive (Incorrect: There Was No Building)', 'False Negative (Incorrect: There Was A Building Here)', 'True Positive (Correct: There Is A Building Here)']\n","    counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n","    percentages = [\"{0:.2%}\".format(value) for value in cm_normalized.flatten()]\n","\n","    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(labels, counts, percentages)]\n","    labels = np.asarray(labels).reshape(2, 2)\n","\n","    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False, center=0)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('True')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# Perform the evaluation\n","plot_training_history(history)\n","y_pred = model.predict(X_test)\n","show_predictions(X_test, y_test, y_pred, threshold=threshold)\n","plot_confusion_matrix(y_test, y_pred, threshold=threshold)\n","print(classification_report(y_test.flatten(), (y_pred.flatten() \u003e threshold).astype(int)))\n","print(\"ROC-AUC:\", roc_auc_score(y_test.flatten(), y_pred.flatten()))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyObE8057mA3RdS/ga2hnsMC","machine_shape":"hm","name":"","provenance":[{"file_id":"1NpShU9m-Nj2D6tCdSxCff3TpL1Y5aKF6","timestamp":1717380265657},{"file_id":"1f1lIddKXevfi94mJs3PuxBxnuM8uZQwo","timestamp":1717380004583},{"file_id":"15BvoeeprCeA1pk7MPCqg6cTM9JuV7IMU","timestamp":1717229218582},{"file_id":"1xDjMyzCNWDd78z51V5LG7-Fb94tRFS6c","timestamp":1717202269266},{"file_id":"1T0bDS1xnUbpTn_HKo-QW-hpHKzAiC40F","timestamp":1717097791182},{"file_id":"1pYfR623jCKtZ1BkOrjZDqoZh0AaLR1dq","timestamp":1717085451334},{"file_id":"1Gyjx9u2SBZzf4fzcEZ-dytx7j6pCy_Tz","timestamp":1717046772304},{"file_id":"16GmAaRyICYXTTeqUaZFMWUtzqK1Fw_nR","timestamp":1717043481212},{"file_id":"1elMNkk0w4e6W0gWUEr4QE6xtozqkygu9","timestamp":1717011460322}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}